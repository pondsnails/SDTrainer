{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pondsnails/SDTrainer/blob/main/SDTrainer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ph_L_yev5oE9",
        "outputId": "f5a95b50-34a1-4779-ffa8-e8ed9af06959"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting stanza\n",
            "  Using cached stanza-1.6.1-py3-none-any.whl (881 kB)\n",
            "Collecting sentence-transformers\n",
            "  Using cached sentence_transformers-2.2.2-py3-none-any.whl\n",
            "Collecting matplotlib\n",
            "  Using cached matplotlib-3.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "Collecting isort\n",
            "  Using cached isort-5.12.0-py3-none-any.whl (91 kB)\n",
            "Collecting torch-xla\n",
            "  Using cached torch_xla-2.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (81.1 MB)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.14.6)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.1)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (from stanza) (2.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from stanza) (1.23.5)\n",
            "Requirement already satisfied: protobuf>=3.15.0 in /usr/local/lib/python3.10/dist-packages (from stanza) (3.20.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from stanza) (2.31.0)\n",
            "Collecting torch>=1.3.0 (from stanza)\n",
            "  Using cached torch-2.1.0-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from stanza) (4.66.1)\n",
            "Collecting transformers<5.0.0,>=4.6.0 (from sentence-transformers)\n",
            "  Using cached transformers-4.34.1-py3-none-any.whl (7.7 MB)\n",
            "Collecting torchvision (from sentence-transformers)\n",
            "  Using cached torchvision-0.16.0-cp310-cp310-manylinux1_x86_64.whl (6.9 MB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.1.99)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.17.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from torch-xla) (1.4.0)\n",
            "Collecting cloud-tpu-client>=0.10.0 (from torch-xla)\n",
            "  Using cached cloud_tpu_client-0.10-py3-none-any.whl (7.4 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from torch-xla) (6.0.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.6)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.18.0)\n",
            "Requirement already satisfied: google-api-python-client==1.8.0 in /usr/local/lib/python3.10/dist-packages (from cloud-tpu-client>=0.10.0->torch-xla) (1.8.0)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (from cloud-tpu-client>=0.10.0->torch-xla) (4.1.3)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla) (0.22.0)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla) (2.17.3)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla) (0.1.1)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla) (1.34.0)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla) (1.16.0)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla) (3.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (2023.7.22)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (3.1.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (12.1.105)\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y -q stanza sentence-transformers transformers transformers[torch] matplotlib isort torch-xla torch torchvision torchaudio cloud-tpu-client\n",
        "!pip install stanza sentence-transformers matplotlib isort torch-xla datasets evaluate\n",
        "!pip install -U transformers[torch]\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.8-cp37-cp37m-linux_x86_64.whl\n",
        "!pip install accelerate -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2-0feW-jGTC",
        "outputId": "06670975-608b-483b-b394-621db40aa33b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Usage:   \n",
            "  pip3 <command> [options]\n",
            "\n",
            "no such option: -y\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.14.6)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.5.0)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (3.4.0)\n",
            "Requirement already satisfied: sagemaker in /usr/local/lib/python3.10/dist-packages (2.196.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.17.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.1.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.34.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from peft) (0.24.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (1.12.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna) (6.7.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.22)\n",
            "Requirement already satisfied: attrs<24,>=23.1.0 in /usr/local/lib/python3.10/dist-packages (from sagemaker) (23.1.0)\n",
            "Requirement already satisfied: boto3<2.0,>=1.26.131 in /usr/local/lib/python3.10/dist-packages (from sagemaker) (1.28.76)\n",
            "Requirement already satisfied: cloudpickle==2.2.1 in /usr/local/lib/python3.10/dist-packages (from sagemaker) (2.2.1)\n",
            "Requirement already satisfied: google-pasta in /usr/local/lib/python3.10/dist-packages (from sagemaker) (0.2.0)\n",
            "Requirement already satisfied: protobuf<5.0,>=3.12 in /usr/local/lib/python3.10/dist-packages (from sagemaker) (3.20.3)\n",
            "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /usr/local/lib/python3.10/dist-packages (from sagemaker) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from sagemaker) (6.8.0)\n",
            "Requirement already satisfied: pathos in /usr/local/lib/python3.10/dist-packages (from sagemaker) (0.3.1)\n",
            "Requirement already satisfied: schema in /usr/local/lib/python3.10/dist-packages (from sagemaker) (0.7.5)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from sagemaker) (4.19.1)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from sagemaker) (3.11.0)\n",
            "Requirement already satisfied: tblib==1.7.0 in /usr/local/lib/python3.10/dist-packages (from sagemaker) (1.7.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (1.2.4)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.5.0)\n",
            "Requirement already satisfied: botocore<1.32.0,>=1.31.76 in /usr/local/lib/python3.10/dist-packages (from boto3<2.0,>=1.26.131->sagemaker) (1.31.76)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3<2.0,>=1.26.131->sagemaker) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from boto3<2.0,>=1.26.131->sagemaker) (0.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker) (3.17.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft) (12.3.52)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from google-pasta->sagemaker) (1.16.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->sagemaker) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->sagemaker) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->sagemaker) (0.10.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: ppft>=1.7.6.7 in /usr/local/lib/python3.10/dist-packages (from pathos->sagemaker) (1.7.6.7)\n",
            "Requirement already satisfied: pox>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from pathos->sagemaker) (0.3.3)\n",
            "Requirement already satisfied: contextlib2>=0.5.5 in /usr/local/lib/python3.10/dist-packages (from schema->sagemaker) (21.6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.14.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
            "fatal: destination path 'apex' already exists and is not an empty directory.\n",
            "/content/apex\n",
            "\n",
            "\n",
            "torch.__version__  = 2.1.0+cu121\n",
            "\n",
            "\n",
            "running install\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` and ``easy_install``.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://github.com/pypa/setuptools/issues/917 for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "writing apex.egg-info/PKG-INFO\n",
            "writing dependency_links to apex.egg-info/dependency_links.txt\n",
            "writing requirements to apex.egg-info/requires.txt\n",
            "writing top-level names to apex.egg-info/top_level.txt\n",
            "reading manifest file 'apex.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/apex\n",
            "copying build/lib/apex/__init__.py -> build/bdist.linux-x86_64/egg/apex\n",
            "creating build/bdist.linux-x86_64/egg/apex/fused_dense\n",
            "copying build/lib/apex/fused_dense/__init__.py -> build/bdist.linux-x86_64/egg/apex/fused_dense\n",
            "copying build/lib/apex/fused_dense/fused_dense.py -> build/bdist.linux-x86_64/egg/apex/fused_dense\n",
            "creating build/bdist.linux-x86_64/egg/apex/RNN\n",
            "copying build/lib/apex/RNN/__init__.py -> build/bdist.linux-x86_64/egg/apex/RNN\n",
            "copying build/lib/apex/RNN/RNNBackend.py -> build/bdist.linux-x86_64/egg/apex/RNN\n",
            "copying build/lib/apex/RNN/cells.py -> build/bdist.linux-x86_64/egg/apex/RNN\n",
            "copying build/lib/apex/RNN/models.py -> build/bdist.linux-x86_64/egg/apex/RNN\n",
            "creating build/bdist.linux-x86_64/egg/apex/mlp\n",
            "copying build/lib/apex/mlp/__init__.py -> build/bdist.linux-x86_64/egg/apex/mlp\n",
            "copying build/lib/apex/mlp/mlp.py -> build/bdist.linux-x86_64/egg/apex/mlp\n",
            "creating build/bdist.linux-x86_64/egg/apex/normalization\n",
            "copying build/lib/apex/normalization/__init__.py -> build/bdist.linux-x86_64/egg/apex/normalization\n",
            "copying build/lib/apex/normalization/fused_layer_norm.py -> build/bdist.linux-x86_64/egg/apex/normalization\n",
            "creating build/bdist.linux-x86_64/egg/apex/multi_tensor_apply\n",
            "copying build/lib/apex/multi_tensor_apply/__init__.py -> build/bdist.linux-x86_64/egg/apex/multi_tensor_apply\n",
            "copying build/lib/apex/multi_tensor_apply/multi_tensor_apply.py -> build/bdist.linux-x86_64/egg/apex/multi_tensor_apply\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/index_mul_2d\n",
            "copying build/lib/apex/contrib/index_mul_2d/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/index_mul_2d\n",
            "copying build/lib/apex/contrib/index_mul_2d/index_mul_2d.py -> build/bdist.linux-x86_64/egg/apex/contrib/index_mul_2d\n",
            "copying build/lib/apex/contrib/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/sparsity\n",
            "copying build/lib/apex/contrib/sparsity/permutation_lib.py -> build/bdist.linux-x86_64/egg/apex/contrib/sparsity\n",
            "copying build/lib/apex/contrib/sparsity/sparse_masklib.py -> build/bdist.linux-x86_64/egg/apex/contrib/sparsity\n",
            "copying build/lib/apex/contrib/sparsity/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/sparsity\n",
            "copying build/lib/apex/contrib/sparsity/asp.py -> build/bdist.linux-x86_64/egg/apex/contrib/sparsity\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/sparsity/permutation_search_kernels\n",
            "copying build/lib/apex/contrib/sparsity/permutation_search_kernels/call_permutation_search_kernels.py -> build/bdist.linux-x86_64/egg/apex/contrib/sparsity/permutation_search_kernels\n",
            "copying build/lib/apex/contrib/sparsity/permutation_search_kernels/exhaustive_search.py -> build/bdist.linux-x86_64/egg/apex/contrib/sparsity/permutation_search_kernels\n",
            "copying build/lib/apex/contrib/sparsity/permutation_search_kernels/permutation_utilities.py -> build/bdist.linux-x86_64/egg/apex/contrib/sparsity/permutation_search_kernels\n",
            "copying build/lib/apex/contrib/sparsity/permutation_search_kernels/channel_swap.py -> build/bdist.linux-x86_64/egg/apex/contrib/sparsity/permutation_search_kernels\n",
            "copying build/lib/apex/contrib/sparsity/permutation_search_kernels/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/sparsity/permutation_search_kernels\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/fmha\n",
            "copying build/lib/apex/contrib/fmha/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/fmha\n",
            "copying build/lib/apex/contrib/fmha/fmha.py -> build/bdist.linux-x86_64/egg/apex/contrib/fmha\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/peer_memory\n",
            "copying build/lib/apex/contrib/peer_memory/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/peer_memory\n",
            "copying build/lib/apex/contrib/peer_memory/peer_memory.py -> build/bdist.linux-x86_64/egg/apex/contrib/peer_memory\n",
            "copying build/lib/apex/contrib/peer_memory/peer_halo_exchanger_1d.py -> build/bdist.linux-x86_64/egg/apex/contrib/peer_memory\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/transducer\n",
            "copying build/lib/apex/contrib/transducer/transducer.py -> build/bdist.linux-x86_64/egg/apex/contrib/transducer\n",
            "copying build/lib/apex/contrib/transducer/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/transducer\n",
            "copying build/lib/apex/contrib/transducer/_transducer_ref.py -> build/bdist.linux-x86_64/egg/apex/contrib/transducer\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/groupbn\n",
            "copying build/lib/apex/contrib/groupbn/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/groupbn\n",
            "copying build/lib/apex/contrib/groupbn/batch_norm.py -> build/bdist.linux-x86_64/egg/apex/contrib/groupbn\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/conv_bias_relu\n",
            "copying build/lib/apex/contrib/conv_bias_relu/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/conv_bias_relu\n",
            "copying build/lib/apex/contrib/conv_bias_relu/conv_bias_relu.py -> build/bdist.linux-x86_64/egg/apex/contrib/conv_bias_relu\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/bottleneck\n",
            "copying build/lib/apex/contrib/bottleneck/test.py -> build/bdist.linux-x86_64/egg/apex/contrib/bottleneck\n",
            "copying build/lib/apex/contrib/bottleneck/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/bottleneck\n",
            "copying build/lib/apex/contrib/bottleneck/halo_exchangers.py -> build/bdist.linux-x86_64/egg/apex/contrib/bottleneck\n",
            "copying build/lib/apex/contrib/bottleneck/bottleneck.py -> build/bdist.linux-x86_64/egg/apex/contrib/bottleneck\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/xentropy\n",
            "copying build/lib/apex/contrib/xentropy/softmax_xentropy.py -> build/bdist.linux-x86_64/egg/apex/contrib/xentropy\n",
            "copying build/lib/apex/contrib/xentropy/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/xentropy\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/group_norm\n",
            "copying build/lib/apex/contrib/group_norm/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/group_norm\n",
            "copying build/lib/apex/contrib/group_norm/group_norm.py -> build/bdist.linux-x86_64/egg/apex/contrib/group_norm\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n",
            "copying build/lib/apex/contrib/optimizers/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n",
            "copying build/lib/apex/contrib/optimizers/fp16_optimizer.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n",
            "copying build/lib/apex/contrib/optimizers/fused_sgd.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n",
            "copying build/lib/apex/contrib/optimizers/fused_adam.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n",
            "copying build/lib/apex/contrib/optimizers/fused_lamb.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n",
            "copying build/lib/apex/contrib/optimizers/distributed_fused_lamb.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n",
            "copying build/lib/apex/contrib/optimizers/distributed_fused_adam.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/cudnn_gbn\n",
            "copying build/lib/apex/contrib/cudnn_gbn/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/cudnn_gbn\n",
            "copying build/lib/apex/contrib/cudnn_gbn/batch_norm.py -> build/bdist.linux-x86_64/egg/apex/contrib/cudnn_gbn\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib/apex/contrib/multihead_attn/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib/apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib/apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib/apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib/apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib/apex/contrib/multihead_attn/self_multihead_attn.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/focal_loss\n",
            "copying build/lib/apex/contrib/focal_loss/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/focal_loss\n",
            "copying build/lib/apex/contrib/focal_loss/focal_loss.py -> build/bdist.linux-x86_64/egg/apex/contrib/focal_loss\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/layer_norm\n",
            "copying build/lib/apex/contrib/layer_norm/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/layer_norm\n",
            "copying build/lib/apex/contrib/layer_norm/layer_norm.py -> build/bdist.linux-x86_64/egg/apex/contrib/layer_norm\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/openfold_triton\n",
            "copying build/lib/apex/contrib/openfold_triton/_layer_norm_config_hopper.py -> build/bdist.linux-x86_64/egg/apex/contrib/openfold_triton\n",
            "copying build/lib/apex/contrib/openfold_triton/_mha_kernel.py -> build/bdist.linux-x86_64/egg/apex/contrib/openfold_triton\n",
            "copying build/lib/apex/contrib/openfold_triton/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/openfold_triton\n",
            "copying build/lib/apex/contrib/openfold_triton/fused_adam_swa.py -> build/bdist.linux-x86_64/egg/apex/contrib/openfold_triton\n",
            "copying build/lib/apex/contrib/openfold_triton/mha.py -> build/bdist.linux-x86_64/egg/apex/contrib/openfold_triton\n",
            "copying build/lib/apex/contrib/openfold_triton/_layer_norm_backward_kernels.py -> build/bdist.linux-x86_64/egg/apex/contrib/openfold_triton\n",
            "copying build/lib/apex/contrib/openfold_triton/layer_norm.py -> build/bdist.linux-x86_64/egg/apex/contrib/openfold_triton\n",
            "copying build/lib/apex/contrib/openfold_triton/_layer_norm_config_ampere.py -> build/bdist.linux-x86_64/egg/apex/contrib/openfold_triton\n",
            "copying build/lib/apex/contrib/openfold_triton/_layer_norm_forward_kernels.py -> build/bdist.linux-x86_64/egg/apex/contrib/openfold_triton\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/clip_grad\n",
            "copying build/lib/apex/contrib/clip_grad/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/clip_grad\n",
            "copying build/lib/apex/contrib/clip_grad/clip_grad.py -> build/bdist.linux-x86_64/egg/apex/contrib/clip_grad\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/test\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/test/index_mul_2d\n",
            "copying build/lib/apex/contrib/test/index_mul_2d/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/index_mul_2d\n",
            "copying build/lib/apex/contrib/test/index_mul_2d/test_index_mul_2d.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/index_mul_2d\n",
            "copying build/lib/apex/contrib/test/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/test\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/test/fmha\n",
            "copying build/lib/apex/contrib/test/fmha/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/fmha\n",
            "copying build/lib/apex/contrib/test/fmha/test_fmha.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/fmha\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/test/peer_memory\n",
            "copying build/lib/apex/contrib/test/peer_memory/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/peer_memory\n",
            "copying build/lib/apex/contrib/test/peer_memory/test_peer_halo_exchange_module.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/peer_memory\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/test/transducer\n",
            "copying build/lib/apex/contrib/test/transducer/test_transducer_joint.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/transducer\n",
            "copying build/lib/apex/contrib/test/transducer/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/transducer\n",
            "copying build/lib/apex/contrib/test/transducer/test_transducer_loss.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/transducer\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/test/conv_bias_relu\n",
            "copying build/lib/apex/contrib/test/conv_bias_relu/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/conv_bias_relu\n",
            "copying build/lib/apex/contrib/test/conv_bias_relu/test_conv_bias_relu.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/conv_bias_relu\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/test/bottleneck\n",
            "copying build/lib/apex/contrib/test/bottleneck/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/bottleneck\n",
            "copying build/lib/apex/contrib/test/bottleneck/test_bottleneck_module.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/bottleneck\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/test/xentropy\n",
            "copying build/lib/apex/contrib/test/xentropy/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/xentropy\n",
            "copying build/lib/apex/contrib/test/xentropy/test_label_smoothing.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/xentropy\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/test/group_norm\n",
            "copying build/lib/apex/contrib/test/group_norm/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/group_norm\n",
            "copying build/lib/apex/contrib/test/group_norm/test_group_norm.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/group_norm\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/test/optimizers\n",
            "copying build/lib/apex/contrib/test/optimizers/test_dist_adam.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/optimizers\n",
            "copying build/lib/apex/contrib/test/optimizers/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/optimizers\n",
            "copying build/lib/apex/contrib/test/optimizers/test_distributed_fused_lamb.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/optimizers\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/test/cudnn_gbn\n",
            "copying build/lib/apex/contrib/test/cudnn_gbn/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/cudnn_gbn\n",
            "copying build/lib/apex/contrib/test/cudnn_gbn/test_cudnn_gbn_with_two_gpus.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/cudnn_gbn\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/test/multihead_attn\n",
            "copying build/lib/apex/contrib/test/multihead_attn/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/multihead_attn\n",
            "copying build/lib/apex/contrib/test/multihead_attn/test_encdec_multihead_attn_norm_add.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/multihead_attn\n",
            "copying build/lib/apex/contrib/test/multihead_attn/test_self_multihead_attn.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/multihead_attn\n",
            "copying build/lib/apex/contrib/test/multihead_attn/test_fast_self_multihead_attn_bias.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/multihead_attn\n",
            "copying build/lib/apex/contrib/test/multihead_attn/test_encdec_multihead_attn.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/multihead_attn\n",
            "copying build/lib/apex/contrib/test/multihead_attn/test_self_multihead_attn_norm_add.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/multihead_attn\n",
            "copying build/lib/apex/contrib/test/multihead_attn/test_mha_fused_softmax.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/multihead_attn\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/test/focal_loss\n",
            "copying build/lib/apex/contrib/test/focal_loss/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/focal_loss\n",
            "copying build/lib/apex/contrib/test/focal_loss/test_focal_loss.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/focal_loss\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/test/layer_norm\n",
            "copying build/lib/apex/contrib/test/layer_norm/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/layer_norm\n",
            "copying build/lib/apex/contrib/test/layer_norm/test_fast_layer_norm.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/layer_norm\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/test/clip_grad\n",
            "copying build/lib/apex/contrib/test/clip_grad/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/clip_grad\n",
            "copying build/lib/apex/contrib/test/clip_grad/test_clip_grad.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/clip_grad\n",
            "creating build/bdist.linux-x86_64/egg/apex/optimizers\n",
            "copying build/lib/apex/optimizers/__init__.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n",
            "copying build/lib/apex/optimizers/fused_sgd.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n",
            "copying build/lib/apex/optimizers/fused_adam.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n",
            "copying build/lib/apex/optimizers/fused_lamb.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n",
            "copying build/lib/apex/optimizers/fused_adagrad.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n",
            "copying build/lib/apex/optimizers/fused_novograd.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n",
            "copying build/lib/apex/optimizers/fused_mixed_precision_lamb.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n",
            "creating build/bdist.linux-x86_64/egg/apex/transformer\n",
            "copying build/lib/apex/transformer/__init__.py -> build/bdist.linux-x86_64/egg/apex/transformer\n",
            "creating build/bdist.linux-x86_64/egg/apex/transformer/_data\n",
            "copying build/lib/apex/transformer/_data/__init__.py -> build/bdist.linux-x86_64/egg/apex/transformer/_data\n",
            "copying build/lib/apex/transformer/_data/_batchsampler.py -> build/bdist.linux-x86_64/egg/apex/transformer/_data\n",
            "copying build/lib/apex/transformer/_ucc_util.py -> build/bdist.linux-x86_64/egg/apex/transformer\n",
            "creating build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel\n",
            "copying build/lib/apex/transformer/tensor_parallel/mappings.py -> build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel\n",
            "copying build/lib/apex/transformer/tensor_parallel/data.py -> build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel\n",
            "copying build/lib/apex/transformer/tensor_parallel/random.py -> build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel\n",
            "copying build/lib/apex/transformer/tensor_parallel/__init__.py -> build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel\n",
            "copying build/lib/apex/transformer/tensor_parallel/utils.py -> build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel\n",
            "copying build/lib/apex/transformer/tensor_parallel/cross_entropy.py -> build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel\n",
            "copying build/lib/apex/transformer/tensor_parallel/memory.py -> build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel\n",
            "copying build/lib/apex/transformer/tensor_parallel/layers.py -> build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel\n",
            "copying build/lib/apex/transformer/utils.py -> build/bdist.linux-x86_64/egg/apex/transformer\n",
            "creating build/bdist.linux-x86_64/egg/apex/transformer/functional\n",
            "copying build/lib/apex/transformer/functional/__init__.py -> build/bdist.linux-x86_64/egg/apex/transformer/functional\n",
            "copying build/lib/apex/transformer/functional/fused_softmax.py -> build/bdist.linux-x86_64/egg/apex/transformer/functional\n",
            "copying build/lib/apex/transformer/log_util.py -> build/bdist.linux-x86_64/egg/apex/transformer\n",
            "creating build/bdist.linux-x86_64/egg/apex/transformer/testing\n",
            "copying build/lib/apex/transformer/testing/global_vars.py -> build/bdist.linux-x86_64/egg/apex/transformer/testing\n",
            "copying build/lib/apex/transformer/testing/commons.py -> build/bdist.linux-x86_64/egg/apex/transformer/testing\n",
            "copying build/lib/apex/transformer/testing/standalone_bert.py -> build/bdist.linux-x86_64/egg/apex/transformer/testing\n",
            "copying build/lib/apex/transformer/testing/distributed_test_base.py -> build/bdist.linux-x86_64/egg/apex/transformer/testing\n",
            "copying build/lib/apex/transformer/testing/__init__.py -> build/bdist.linux-x86_64/egg/apex/transformer/testing\n",
            "copying build/lib/apex/transformer/testing/standalone_transformer_lm.py -> build/bdist.linux-x86_64/egg/apex/transformer/testing\n",
            "copying build/lib/apex/transformer/testing/arguments.py -> build/bdist.linux-x86_64/egg/apex/transformer/testing\n",
            "copying build/lib/apex/transformer/testing/standalone_gpt.py -> build/bdist.linux-x86_64/egg/apex/transformer/testing\n",
            "creating build/bdist.linux-x86_64/egg/apex/transformer/layers\n",
            "copying build/lib/apex/transformer/layers/__init__.py -> build/bdist.linux-x86_64/egg/apex/transformer/layers\n",
            "copying build/lib/apex/transformer/layers/layer_norm.py -> build/bdist.linux-x86_64/egg/apex/transformer/layers\n",
            "creating build/bdist.linux-x86_64/egg/apex/transformer/amp\n",
            "copying build/lib/apex/transformer/amp/grad_scaler.py -> build/bdist.linux-x86_64/egg/apex/transformer/amp\n",
            "copying build/lib/apex/transformer/amp/__init__.py -> build/bdist.linux-x86_64/egg/apex/transformer/amp\n",
            "creating build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel\n",
            "copying build/lib/apex/transformer/pipeline_parallel/p2p_communication.py -> build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel\n",
            "copying build/lib/apex/transformer/pipeline_parallel/__init__.py -> build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel\n",
            "copying build/lib/apex/transformer/pipeline_parallel/utils.py -> build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel\n",
            "creating build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/schedules\n",
            "copying build/lib/apex/transformer/pipeline_parallel/schedules/fwd_bwd_no_pipelining.py -> build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/schedules\n",
            "copying build/lib/apex/transformer/pipeline_parallel/schedules/__init__.py -> build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/schedules\n",
            "copying build/lib/apex/transformer/pipeline_parallel/schedules/common.py -> build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/schedules\n",
            "copying build/lib/apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_with_interleaving.py -> build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/schedules\n",
            "copying build/lib/apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_without_interleaving.py -> build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/schedules\n",
            "copying build/lib/apex/transformer/pipeline_parallel/_timers.py -> build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel\n",
            "copying build/lib/apex/transformer/parallel_state.py -> build/bdist.linux-x86_64/egg/apex/transformer\n",
            "copying build/lib/apex/transformer/microbatches.py -> build/bdist.linux-x86_64/egg/apex/transformer\n",
            "copying build/lib/apex/transformer/enums.py -> build/bdist.linux-x86_64/egg/apex/transformer\n",
            "copying build/lib/apex/_autocast_utils.py -> build/bdist.linux-x86_64/egg/apex\n",
            "creating build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib/apex/amp/__init__.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib/apex/amp/opt.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib/apex/amp/rnn_compat.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib/apex/amp/wrap.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib/apex/amp/scaler.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib/apex/amp/utils.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib/apex/amp/_initialize.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib/apex/amp/handle.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib/apex/amp/_amp_state.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib/apex/amp/frontend.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "creating build/bdist.linux-x86_64/egg/apex/amp/lists\n",
            "copying build/lib/apex/amp/lists/tensor_overrides.py -> build/bdist.linux-x86_64/egg/apex/amp/lists\n",
            "copying build/lib/apex/amp/lists/functional_overrides.py -> build/bdist.linux-x86_64/egg/apex/amp/lists\n",
            "copying build/lib/apex/amp/lists/__init__.py -> build/bdist.linux-x86_64/egg/apex/amp/lists\n",
            "copying build/lib/apex/amp/lists/torch_overrides.py -> build/bdist.linux-x86_64/egg/apex/amp/lists\n",
            "copying build/lib/apex/amp/__version__.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib/apex/amp/compat.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib/apex/amp/_process_optimizer.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib/apex/amp/amp.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "creating build/bdist.linux-x86_64/egg/apex/fp16_utils\n",
            "copying build/lib/apex/fp16_utils/loss_scaler.py -> build/bdist.linux-x86_64/egg/apex/fp16_utils\n",
            "copying build/lib/apex/fp16_utils/fp16util.py -> build/bdist.linux-x86_64/egg/apex/fp16_utils\n",
            "copying build/lib/apex/fp16_utils/__init__.py -> build/bdist.linux-x86_64/egg/apex/fp16_utils\n",
            "copying build/lib/apex/fp16_utils/fp16_optimizer.py -> build/bdist.linux-x86_64/egg/apex/fp16_utils\n",
            "creating build/bdist.linux-x86_64/egg/apex/parallel\n",
            "copying build/lib/apex/parallel/optimized_sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
            "copying build/lib/apex/parallel/LARC.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
            "copying build/lib/apex/parallel/multiproc.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
            "copying build/lib/apex/parallel/__init__.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
            "copying build/lib/apex/parallel/optimized_sync_batchnorm.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
            "copying build/lib/apex/parallel/sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
            "copying build/lib/apex/parallel/sync_batchnorm.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
            "copying build/lib/apex/parallel/distributed.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/fused_dense/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/fused_dense/fused_dense.py to fused_dense.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/RNN/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/RNN/RNNBackend.py to RNNBackend.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/RNN/cells.py to cells.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/RNN/models.py to models.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/mlp/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/mlp/mlp.py to mlp.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/normalization/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/normalization/fused_layer_norm.py to fused_layer_norm.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/multi_tensor_apply/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/multi_tensor_apply/multi_tensor_apply.py to multi_tensor_apply.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/index_mul_2d/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/index_mul_2d/index_mul_2d.py to index_mul_2d.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/sparsity/permutation_lib.py to permutation_lib.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/sparsity/sparse_masklib.py to sparse_masklib.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/sparsity/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/sparsity/asp.py to asp.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/sparsity/permutation_search_kernels/call_permutation_search_kernels.py to call_permutation_search_kernels.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/sparsity/permutation_search_kernels/exhaustive_search.py to exhaustive_search.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/sparsity/permutation_search_kernels/permutation_utilities.py to permutation_utilities.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/sparsity/permutation_search_kernels/channel_swap.py to channel_swap.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/sparsity/permutation_search_kernels/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/fmha/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/fmha/fmha.py to fmha.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/peer_memory/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/peer_memory/peer_memory.py to peer_memory.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/peer_memory/peer_halo_exchanger_1d.py to peer_halo_exchanger_1d.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/transducer/transducer.py to transducer.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/transducer/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/transducer/_transducer_ref.py to _transducer_ref.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/groupbn/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/groupbn/batch_norm.py to batch_norm.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/conv_bias_relu/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/conv_bias_relu/conv_bias_relu.py to conv_bias_relu.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/bottleneck/test.py to test.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/bottleneck/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/bottleneck/halo_exchangers.py to halo_exchangers.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/bottleneck/bottleneck.py to bottleneck.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/xentropy/softmax_xentropy.py to softmax_xentropy.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/xentropy/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/group_norm/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/group_norm/group_norm.py to group_norm.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/fp16_optimizer.py to fp16_optimizer.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/fused_sgd.py to fused_sgd.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/fused_adam.py to fused_adam.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/fused_lamb.py to fused_lamb.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/distributed_fused_lamb.py to distributed_fused_lamb.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/distributed_fused_adam.py to distributed_fused_adam.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/cudnn_gbn/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/cudnn_gbn/batch_norm.py to batch_norm.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/encdec_multihead_attn.py to encdec_multihead_attn.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/self_multihead_attn_func.py to self_multihead_attn_func.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py to fast_self_multihead_attn_func.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py to fast_encdec_multihead_attn_norm_add_func.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/mask_softmax_dropout_func.py to mask_softmax_dropout_func.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/encdec_multihead_attn_func.py to encdec_multihead_attn_func.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py to fast_encdec_multihead_attn_func.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/self_multihead_attn.py to self_multihead_attn.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py to fast_self_multihead_attn_norm_add_func.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/focal_loss/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/focal_loss/focal_loss.py to focal_loss.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/layer_norm/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/layer_norm/layer_norm.py to layer_norm.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/openfold_triton/_layer_norm_config_hopper.py to _layer_norm_config_hopper.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/openfold_triton/_mha_kernel.py to _mha_kernel.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/openfold_triton/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/openfold_triton/fused_adam_swa.py to fused_adam_swa.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/openfold_triton/mha.py to mha.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/openfold_triton/_layer_norm_backward_kernels.py to _layer_norm_backward_kernels.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/openfold_triton/layer_norm.py to layer_norm.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/openfold_triton/_layer_norm_config_ampere.py to _layer_norm_config_ampere.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/openfold_triton/_layer_norm_forward_kernels.py to _layer_norm_forward_kernels.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/clip_grad/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/clip_grad/clip_grad.py to clip_grad.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/index_mul_2d/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/index_mul_2d/test_index_mul_2d.py to test_index_mul_2d.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/fmha/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/fmha/test_fmha.py to test_fmha.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/peer_memory/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/peer_memory/test_peer_halo_exchange_module.py to test_peer_halo_exchange_module.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/transducer/test_transducer_joint.py to test_transducer_joint.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/transducer/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/transducer/test_transducer_loss.py to test_transducer_loss.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/conv_bias_relu/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/conv_bias_relu/test_conv_bias_relu.py to test_conv_bias_relu.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/bottleneck/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/bottleneck/test_bottleneck_module.py to test_bottleneck_module.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/xentropy/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/xentropy/test_label_smoothing.py to test_label_smoothing.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/group_norm/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/group_norm/test_group_norm.py to test_group_norm.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/optimizers/test_dist_adam.py to test_dist_adam.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/optimizers/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/optimizers/test_distributed_fused_lamb.py to test_distributed_fused_lamb.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/cudnn_gbn/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/cudnn_gbn/test_cudnn_gbn_with_two_gpus.py to test_cudnn_gbn_with_two_gpus.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/multihead_attn/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/multihead_attn/test_encdec_multihead_attn_norm_add.py to test_encdec_multihead_attn_norm_add.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/multihead_attn/test_self_multihead_attn.py to test_self_multihead_attn.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/multihead_attn/test_fast_self_multihead_attn_bias.py to test_fast_self_multihead_attn_bias.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/multihead_attn/test_encdec_multihead_attn.py to test_encdec_multihead_attn.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/multihead_attn/test_self_multihead_attn_norm_add.py to test_self_multihead_attn_norm_add.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/multihead_attn/test_mha_fused_softmax.py to test_mha_fused_softmax.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/focal_loss/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/focal_loss/test_focal_loss.py to test_focal_loss.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/layer_norm/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/layer_norm/test_fast_layer_norm.py to test_fast_layer_norm.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/clip_grad/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/clip_grad/test_clip_grad.py to test_clip_grad.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/fused_sgd.py to fused_sgd.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/fused_adam.py to fused_adam.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/fused_lamb.py to fused_lamb.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/fused_adagrad.py to fused_adagrad.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/fused_novograd.py to fused_novograd.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/fused_mixed_precision_lamb.py to fused_mixed_precision_lamb.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/_data/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/_data/_batchsampler.py to _batchsampler.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/_ucc_util.py to _ucc_util.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel/mappings.py to mappings.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel/data.py to data.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel/random.py to random.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel/utils.py to utils.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel/cross_entropy.py to cross_entropy.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel/memory.py to memory.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel/layers.py to layers.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/utils.py to utils.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/functional/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/functional/fused_softmax.py to fused_softmax.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/log_util.py to log_util.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/testing/global_vars.py to global_vars.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/testing/commons.py to commons.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/testing/standalone_bert.py to standalone_bert.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/testing/distributed_test_base.py to distributed_test_base.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/testing/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/testing/standalone_transformer_lm.py to standalone_transformer_lm.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/testing/arguments.py to arguments.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/testing/standalone_gpt.py to standalone_gpt.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/layers/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/layers/layer_norm.py to layer_norm.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/amp/grad_scaler.py to grad_scaler.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/amp/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/p2p_communication.py to p2p_communication.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/utils.py to utils.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/schedules/fwd_bwd_no_pipelining.py to fwd_bwd_no_pipelining.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/schedules/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/schedules/common.py to common.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_with_interleaving.py to fwd_bwd_pipelining_with_interleaving.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_without_interleaving.py to fwd_bwd_pipelining_without_interleaving.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/_timers.py to _timers.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/parallel_state.py to parallel_state.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/microbatches.py to microbatches.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/enums.py to enums.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/_autocast_utils.py to _autocast_utils.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/opt.py to opt.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/rnn_compat.py to rnn_compat.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/wrap.py to wrap.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/scaler.py to scaler.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/utils.py to utils.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/_initialize.py to _initialize.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/handle.py to handle.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/_amp_state.py to _amp_state.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/frontend.py to frontend.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/lists/tensor_overrides.py to tensor_overrides.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/lists/functional_overrides.py to functional_overrides.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/lists/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/lists/torch_overrides.py to torch_overrides.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/__version__.py to __version__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/compat.py to compat.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/_process_optimizer.py to _process_optimizer.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/amp.py to amp.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/fp16_utils/loss_scaler.py to loss_scaler.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/fp16_utils/fp16util.py to fp16util.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/fp16_utils/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/fp16_utils/fp16_optimizer.py to fp16_optimizer.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/optimized_sync_batchnorm_kernel.py to optimized_sync_batchnorm_kernel.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/LARC.py to LARC.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/multiproc.py to multiproc.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/optimized_sync_batchnorm.py to optimized_sync_batchnorm.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/sync_batchnorm_kernel.py to sync_batchnorm_kernel.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/sync_batchnorm.py to sync_batchnorm.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/distributed.py to distributed.cpython-310.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying apex.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying apex.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying apex.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying apex.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying apex.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "apex.contrib.optimizers.__pycache__.distributed_fused_adam.cpython-310: module MAY be using inspect.stack\n",
            "creating 'dist/apex-0.1-py3.10.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing apex-0.1-py3.10.egg\n",
            "removing '/usr/local/lib/python3.10/dist-packages/apex-0.1-py3.10.egg' (and everything under it)\n",
            "creating /usr/local/lib/python3.10/dist-packages/apex-0.1-py3.10.egg\n",
            "Extracting apex-0.1-py3.10.egg to /usr/local/lib/python3.10/dist-packages\n",
            "apex 0.1 is already the active version in easy-install.pth\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/apex-0.1-py3.10.egg\n",
            "Processing dependencies for apex==0.1\n",
            "Searching for packaging==23.2\n",
            "Best match: packaging 23.2\n",
            "Adding packaging 23.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Finished processing dependencies for apex==0.1\n"
          ]
        }
      ],
      "source": [
        "!pip -y uninstall apex datasets peft optuna sagemaker\n",
        "!pip install datasets peft optuna sagemaker\n",
        "!git clone https://github.com/NVIDIA/apex\n",
        "%cd /content/apex\n",
        "!python setup.py install\n",
        "!cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVCAfeO9kkZN",
        "outputId": "e71d87e6-be35-4962-a520-769c653fbebe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnlvxCYr611N",
        "outputId": "1f97520f-5196-4cd2-8d24-df26fac80bf8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'cls.seq_relationship.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertForMaskedLM\n",
        "\n",
        "model_checkpoint = \"bert-base-cased\"\n",
        "model = BertForMaskedLM.from_pretrained(model_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNnztKQeLUS-"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, BertForMaskedLM, AdamW, DataCollatorWithPadding, TrainingArguments, Trainer\n",
        "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
        "from tqdm import tqdm\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import math\n",
        "import torch\n",
        "import json\n",
        "import glob\n",
        "import re\n",
        "import numpy as np\n",
        "import stanza"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129,
          "referenced_widgets": [
            "83cbbc391f4b4d369345b8d293ec20b1",
            "554392641ce94926b63f3aa9b59231da",
            "f5fb339912574bcbb6a4930c546c1021",
            "07ceda4271c74db7938f5c1c964ab8d2",
            "b7fdaf13a7d74176b2ad902dde8b371d",
            "8a508c11db0c454597b9271b15779cf6",
            "111ba9fc9340411b8200851075ae3da8",
            "bf7d168cc8ef4a1ca37f176a23061f14",
            "d264a1b855734178aa27c3e896a8e0e0",
            "6b1f9105124e4c98a73411afd510a0a7",
            "b7446b17d6f945b182b5582e98c40477"
          ]
        },
        "id": "kB4wOTe3ivXf",
        "outputId": "8b5a404c-263f-4dc6-e81e-2c6f5eebbdb6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "83cbbc391f4b4d369345b8d293ec20b1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json:   0%|   "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:stanza:Downloading default packages for language: en (English) ...\n",
            "INFO:stanza:File exists: /root/stanza_resources/en/default.zip\n",
            "INFO:stanza:Finished downloading models and saved to /root/stanza_resources.\n"
          ]
        }
      ],
      "source": [
        "stanza.download('en')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAJnT3kziusx"
      },
      "outputs": [],
      "source": [
        "valid = [glob.glob(\"/content/drive/MyDrive/data/CLOTH/valid/middle/*\"),glob.glob(\"/content/drive/MyDrive/data/CLOTH/valid/high/*\")]\n",
        "test = [glob.glob(\"/content/drive/MyDrive/data/CLOTH/test/middle/*\"),glob.glob(\"/content/drive/MyDrive/data/CLOTH/test/high/*\")]\n",
        "train = [glob.glob(\"/content/drive/MyDrive/data/CLOTH/train/middle/*\"),glob.glob(\"/content/drive/MyDrive/data/CLOTH/train/high/*\")]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340,
          "referenced_widgets": [
            "1bdd38742d244c05ba5c09c0d08c73d2",
            "489384badc044a74945ed68d7fbef450",
            "0453a0a1c8b643359ff8b5afc9330310",
            "c1a3dce0157e48cfb90dbaaae87a4a2c",
            "afd436f8d349410d9c7c2d7a0dc0c705",
            "d9c947f871504501be96de21be62d69a",
            "3a4dc12f7546467684ef5745655f7f59",
            "b680b42fd9e246e2909355d511251ff5",
            "af5c8e97c00545caab93326d9005f37e",
            "af4684ee39274c98912e6ccbaa8fab92",
            "55d0b4c05a8f4ca3b8cdbcf6db7bbbbf"
          ]
        },
        "id": "wUoPhrgwiw6S",
        "outputId": "e48a0397-0b60-4fe0-edd9-0982d0ffb0e5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:stanza:Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1bdd38742d244c05ba5c09c0d08c73d2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json:   0%|   "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:stanza:Loading these models for language: en (English):\n",
            "========================\n",
            "| Processor | Package  |\n",
            "------------------------\n",
            "| tokenize  | combined |\n",
            "========================\n",
            "\n",
            "INFO:stanza:Using device: cuda\n",
            "INFO:stanza:Loading: tokenize\n",
            "INFO:stanza:Done loading processors!\n",
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'cls.seq_relationship.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "model_checkpoint = \"bert-base-cased\"\n",
        "stanza_pipeline = stanza.Pipeline('en', processors='tokenize')\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "model = BertForMaskedLM.from_pretrained(model_checkpoint)\n",
        "similarity_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mpa44HGGKo14"
      },
      "source": [
        "# "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o2ZM77SIYUSD"
      },
      "outputs": [],
      "source": [
        "def compare_with_semantic_differential(word):\n",
        "    # \"positive\"  \"passive\" \n",
        "    semantic_differential = [\n",
        "        similarity_model.encode(\"positive\", convert_to_tensor=True),\n",
        "        similarity_model.encode(\"negative\", convert_to_tensor=True),\n",
        "        similarity_model.encode(\"strong\", convert_to_tensor=True),\n",
        "        similarity_model.encode(\"weak\", convert_to_tensor=True),\n",
        "        similarity_model.encode(\"active\", convert_to_tensor=True),\n",
        "        similarity_model.encode(\"passive\", convert_to_tensor=True),\n",
        "    ]\n",
        "\n",
        "    # \n",
        "    encoded_word = similarity_model.encode(word, convert_to_tensor=True)\n",
        "\n",
        "    # \n",
        "    temp_list = [0] * 6\n",
        "\n",
        "    # \n",
        "    for index, semantic in enumerate(semantic_differential):\n",
        "        temp_list[index] = util.pytorch_cos_sim(semantic, encoded_word)[0][0].item()\n",
        "\n",
        "    return temp_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ab84ipnXYXmM"
      },
      "outputs": [],
      "source": [
        "def compute_loss(kind, predictions, answer_labels):\n",
        "    # \n",
        "    entropies = []\n",
        "\n",
        "    # predictionsanswer_labels\n",
        "    for batch_index in range(len(predictions)):\n",
        "        # \n",
        "        p = answer_labels[batch_index]\n",
        "        q = predictions[batch_index]\n",
        "\n",
        "        # \n",
        "        entropy = 0\n",
        "\n",
        "        p_total = sum(predictions)\n",
        "        q_total = sum(answer_labels)\n",
        "\n",
        "        # KL\n",
        "        for index in range(6):\n",
        "            if kind == \"cross_entropy\":\n",
        "                entropy -= (p / p_total) * np.log(q / q_total)\n",
        "\n",
        "            if kind == \"kl_divergence\":\n",
        "                entropy += (p / p_total) * np.log((p / p_total)) - (\n",
        "                    (p / p_total)\n",
        "                ) * np.log(q / q_total)\n",
        "\n",
        "        entropies.append(entropy)\n",
        "\n",
        "    # floattorch\n",
        "    return torch.tensor(entropies, dtype=torch.float)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8QiY7nWcUq-"
      },
      "source": [
        "# "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDR1NRt04__2"
      },
      "outputs": [],
      "source": [
        "from copy import deepcopy\n",
        "\n",
        "def create_dataset(dfs):\n",
        "    lists = []\n",
        "    text = []\n",
        "    label = []\n",
        "    # dfs\n",
        "    print(len(dfs))\n",
        "    for file_index, file in tqdm(enumerate(dfs)):\n",
        "        with open(file, \"r\") as f:\n",
        "            j = json.load(f)\n",
        "        article = j[\"article\"]\n",
        "        options = j[\"options\"]\n",
        "        answers = j[\"answers\"]\n",
        "\n",
        "        article = article.replace(\"\\n\", \" \")\n",
        "        doc = stanza_pipeline(article)\n",
        "\n",
        "        masks = []\n",
        "        docs = []\n",
        "        questions = []\n",
        "        corrects = []\n",
        "\n",
        "        # Article\n",
        "        for d, sentence in enumerate(doc.sentences):\n",
        "            docs.append([])\n",
        "            for t, token in enumerate(sentence.tokens):\n",
        "                docs[d].append(token.text)\n",
        "                if token.text == \"_\":\n",
        "                    masks.append([d, t])\n",
        "\n",
        "        copied_docs = deepcopy(docs)\n",
        "\n",
        "        # \n",
        "        for k in range(len(answers)):\n",
        "            temp_answer = str(answers[k]).translate(\n",
        "                str.maketrans({\"A\": \"0\", \"B\": \"1\", \"C\": \"2\", \"D\": \"3\"})\n",
        "            )\n",
        "            answers[k] = options[k][int(temp_answer)]\n",
        "            copied_docs[masks[k][0]][masks[k][1]] = answers[k]\n",
        "\n",
        "        # \n",
        "        for m, mask in enumerate(masks):\n",
        "            docs[mask[0]][mask[1]] = answers[m]\n",
        "\n",
        "            docs[mask[0]][mask[1]] = \"[MASK]\"\n",
        "\n",
        "            if mask[0] == 0:\n",
        "                questions.append(\" \".join(docs[mask[0]]))\n",
        "                corrects.append(\" \".join(copied_docs[mask[0]]))\n",
        "            else:\n",
        "                questions.append(\" \".join(docs[mask[0] - 1] + docs[mask[0]]))\n",
        "                corrects.append(\" \".join(copied_docs[mask[0] - 1] + copied_docs[mask[0]]))\n",
        "\n",
        "            docs[mask[0]][mask[1]] = answers[m]\n",
        "\n",
        "            text.append(questions[m])\n",
        "            label.append(corrects[m])\n",
        "\n",
        "        if file_index >= 100:\n",
        "          return { \"text\": label}\n",
        "\n",
        "    return { \"text\": label}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XJKxSRX88Fu",
        "outputId": "84e93de1-a572-44c7-c121-1ee7e8f97d1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "805\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100it [00:02, 49.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5513\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100it [00:02, 45.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "813\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100it [00:02, 43.67it/s]\n"
          ]
        }
      ],
      "source": [
        "import itertools\n",
        "from datasets import Dataset\n",
        "\n",
        "valid_dataset = Dataset.from_dict(create_dataset(list(itertools.chain.from_iterable(valid))))\n",
        "train_dataset = Dataset.from_dict(create_dataset(list(itertools.chain.from_iterable(train))))\n",
        "test_dataset = Dataset.from_dict(create_dataset(list(itertools.chain.from_iterable(test))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356,
          "referenced_widgets": [
            "4f5fc896af4b46b5b38545dd167563de",
            "a449fb9e7e8d4f91b831d6ab9209aa99",
            "cc81a70d3c86472989b5940b983fe59f",
            "aa80134e2f944ee9ae2f26ba76d74169",
            "a7e8270702414b86ab8d04a0558cff83",
            "50f5fdd28ce4430cbcd7d9b823f06658",
            "eacd5a5c51eb4a56a90f891a35ee8740",
            "70ce6a6ce6b6423987482561e873682a",
            "74454516debf4a54b1e546f2dbd837ab",
            "4f958913846143a3949c7b0881d5c801",
            "2fdb6c338c7244cd8c8fdcabbf3ca6e7",
            "a59c9ae50b864d048c7d7b894c9e0fec",
            "9c0d09550567447fbcdf4fa743872bb8",
            "c31b8aed83fb416092f0c552c694a229",
            "cab14b860a26471dab2bdbbd29122e94",
            "62a0cda9d559481398d7e685b69d452d",
            "f7ee10a2c1094117a8631aa2a7adcd60",
            "5a17d1414cb046f1a11e27f4bac4645c",
            "be30e8d4605c41a39130f9fb8e31a029",
            "b0a9794e325b4906ab04cc03516a44ef",
            "af21f480704f4d74a8f88cfc54473d0c",
            "9f7b27a5f0ea4ba6b6a2368d73ca56bf",
            "ea6fcff1a76e43868bdfb4d02951d072",
            "459d717118a149f8ac13f414d046fe41",
            "a5a01b0ea128464c92cdbce02dc99ac3",
            "25b2438159304b9797601624984a7cb0",
            "3deb340cc3d8446ca385474465b0d57e",
            "5e0d7ac838f748dead98b6d50e20a80b",
            "8203ea24ccaf42e7981fce149bb1c0f8",
            "74b0d0d542fb4069861154a9529c5b87",
            "544020e7ba3a4f538c08ec1f5498ce7b",
            "f8fdf2d0a017425e8f5b1bd30a0f2c90",
            "c000c04a5fb14c6786ee1d4e2983e260"
          ]
        },
        "id": "gu0Zsgm85AUI",
        "outputId": "80df8b04-b0b4-45cc-c075-e97d6375a924"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4f5fc896af4b46b5b38545dd167563de",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/949 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a59c9ae50b864d048c7d7b894c9e0fec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/931 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ea6fcff1a76e43868bdfb4d02951d072",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/926 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'word_ids'],\n",
              "        num_rows: 949\n",
              "    })\n",
              "    valid: Dataset({\n",
              "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'word_ids'],\n",
              "        num_rows: 931\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'word_ids'],\n",
              "        num_rows: 926\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from datasets import DatasetDict\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    result = tokenizer(examples[\"text\"])\n",
        "    if tokenizer.is_fast:\n",
        "        result[\"word_ids\"] = [result.word_ids(i) for i in range(len(result[\"input_ids\"]))]\n",
        "    return result\n",
        "\n",
        "\n",
        "# Use batched=True to activate fast multithreading!\n",
        "tokenized_train_datasets = train_dataset.map(\n",
        "    tokenize_function, batched=True, remove_columns=[\"text\"]\n",
        ")\n",
        "tokenized_valid_datasets = valid_dataset.map(\n",
        "    tokenize_function, batched=True, remove_columns=[\"text\"]\n",
        ")\n",
        "tokenized_test_datasets = test_dataset.map(\n",
        "    tokenize_function, batched=True, remove_columns=[\"text\"]\n",
        ")\n",
        "\n",
        "tokenized_datasets = DatasetDict(\n",
        "    {\n",
        "        \"train\": tokenized_train_datasets,\n",
        "        \"valid\": tokenized_valid_datasets,\n",
        "        \"test\": tokenized_test_datasets,\n",
        "    }\n",
        ")\n",
        "\n",
        "tokenized_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51BhSyPQ5Fek"
      },
      "outputs": [],
      "source": [
        "chunk_size = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWF8_-c65Iyc",
        "outputId": "680f8f70-5d39-4d87-85e3-531f998f440c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'>>> Review 0 length: 18'\n",
            "'>>> Review 1 length: 23'\n",
            "'>>> Review 2 length: 18'\n"
          ]
        }
      ],
      "source": [
        "# Slicing produces a list of lists for each feature\n",
        "tokenized_samples = tokenized_datasets[\"train\"][:3]\n",
        "\n",
        "for idx, sample in enumerate(tokenized_samples[\"input_ids\"]):\n",
        "    print(f\"'>>> Review {idx} length: {len(sample)}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEsjoCww5JO_",
        "outputId": "a18e3ffd-20fd-4cbc-d979-cb4a65f9bc80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'>>> Concatenated reviews length: 59'\n"
          ]
        }
      ],
      "source": [
        "concatenated_examples = {\n",
        "    k: sum(tokenized_samples[k], []) for k in tokenized_samples.keys()\n",
        "}\n",
        "total_length = len(concatenated_examples[\"input_ids\"])\n",
        "print(f\"'>>> Concatenated reviews length: {total_length}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWoJd3u95KpK",
        "outputId": "ec09901d-c6f8-44b3-c3f2-7bc571d2f977"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'>>> Chunk length: 59'\n"
          ]
        }
      ],
      "source": [
        "chunks = {\n",
        "    k: [t[i : i + chunk_size] for i in range(0, total_length, chunk_size)]\n",
        "    for k, t in concatenated_examples.items()\n",
        "}\n",
        "\n",
        "for chunk in chunks[\"input_ids\"]:\n",
        "    print(f\"'>>> Chunk length: {len(chunk)}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flwUX6mR5MqC"
      },
      "outputs": [],
      "source": [
        "def group_texts(examples):\n",
        "    # Concatenate all texts\n",
        "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
        "    # Compute length of concatenated texts\n",
        "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
        "    # We drop the last chunk if it's smaller than chunk_size\n",
        "    total_length = (total_length // chunk_size) * chunk_size\n",
        "    # Split by chunks of max_len\n",
        "    result = {\n",
        "        k: [t[i : i + chunk_size] for i in range(0, total_length, chunk_size)]\n",
        "        for k, t in concatenated_examples.items()\n",
        "    }\n",
        "    # Create a new labels column\n",
        "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356,
          "referenced_widgets": [
            "241ad8cd6b254189bf918b4c4e66f0d8",
            "70a9a2e1749a4e5f889a90ffcfe698ed",
            "35dbe9271dd6412181d965508716c003",
            "66aaa56e580b425dad6e54f2a00f2162",
            "43ae62d6c16d47608fda89136ff0d098",
            "982d940c9e5740d687754b6d6e1d17bd",
            "0f20408cfd354868964c1ac96e15182d",
            "24d835c4b7b04ee282b627ae802065b4",
            "239ec50da2214ea890d96330dbafe1d4",
            "d14c7c9d8b8d452b9ae62c6bb8ea5b1a",
            "a37f65ba164443df8c4730ebe946cef9",
            "0359ed9cd3974808af645a0208463ada",
            "a4791e112d3d471f980214d5ce341f10",
            "88ec7ae09c57497698889a586bac25ee",
            "8cb516b32ce14f559d010e016859c22b",
            "705030b7eeab4a81af9f4b6b38adebf9",
            "c3d69fd5b42246829bdf3095d3551fb7",
            "84c865e110444241829fb055fc141238",
            "f59a2ee833bc419081b6e10f85082e48",
            "368d6d48189343c08a792e90c09edf96",
            "6832f2df5aba4a2984fb476d06ed3810",
            "12991808ffbb4985949a11aac9a404b6",
            "4f065cfca15642a8bc542a2f1fbfe498",
            "52a007efacae40e3b84ad50c64241fe7",
            "8acb0b32346e436ca9df24d57360d3c7",
            "c77858d4289f4fc8b9f20d3b84d57ea6",
            "37984bf0b6bf4af8b8e96f78e35ea909",
            "3e3e1bf871b045f99b7ef5bad0fb50e6",
            "70af0584e74d483ca042c92ab44af828",
            "fe3d64aa61be496fb000f8410ef3cc07",
            "057a196745b64187b3235e8e03b3555c",
            "1e2830eeff51412d88be2d8c1c25fabc",
            "7ce0cc952d5048aa9491f9da9fdcb17f"
          ]
        },
        "id": "Ol7Q_EBM5OPz",
        "outputId": "694a6418-5435-461f-bbbe-a33aedece148"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "241ad8cd6b254189bf918b4c4e66f0d8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/949 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0359ed9cd3974808af645a0208463ada",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/931 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4f065cfca15642a8bc542a2f1fbfe498",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/926 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'word_ids', 'labels'],\n",
              "        num_rows: 241\n",
              "    })\n",
              "    valid: Dataset({\n",
              "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'word_ids', 'labels'],\n",
              "        num_rows: 225\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'word_ids', 'labels'],\n",
              "        num_rows: 230\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lm_datasets = tokenized_datasets.map(group_texts, batched=True)\n",
        "lm_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "NoAlLD8F5QEd",
        "outputId": "d7ca9eb1-8046-4db4-bb66-9c7275cb666a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'are all at good 7. prices. [SEP] [CLS] We have many fruits, like oranges, pears and strawberries. Our store is open 8. from 9 : 00 am to 9 : 00 pm every day. [SEP] [CLS] Our store is open 8. from 9 : 00 am to 9 : 00 pm every day. 9. You want it, we have it. [SEP] [CLS] Then you can have a 10. big dinner with your family on Christmas Day. [SEP] [CLS] Each nation has many good people who help to take care of others. For example, some high school and college students in the USA often spend many hours as volunteers'"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.decode(lm_datasets[\"train\"][1][\"input_ids\"])\n",
        "tokenizer.decode(lm_datasets[\"train\"][1][\"labels\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "423M2ZOl5TUc"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForLanguageModeling\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVk8lji45VQO",
        "outputId": "bafbc7b3-c351-471b-b454-b68031509e45"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "'>>> [CLS] Christmas Day [MASK] next Sunday. Our 1. food is on sale for [MASK]. [SEP] [CLS] 2. [MASK] and have a look. We have hamb [MASK]s 3. [MASK] only 7 dollars [MASK] [SEP] [CLS] Do you [MASK] snacks? We [MASK]. sell all kinds of [MASK]s. [SEP] [CLS] We 4. sell all [MASK] of snacks. You can also buy vegetables [MASK] [MASK] store - - potatoes, 5. carrots... [SEP] [CLS] You can also [MASK] vegetables at our store - - potatoes, 5. carrots... They are all 6. nice. [SEP] [CLS] They are [MASK] 6. nice. [MASK] drinks'\n",
            "\n",
            "'>>> are [MASK] at good 7 [MASK] prices. [SEP] [CLS] We have many fruits, like [MASK]s, pears and straw [MASK]. Our store is open 8. from 9 : [MASK] am to 9 : [MASK] pm every day. [SEP] [CLS] Our store ramp open 8. from 9 : 00 am to [MASK] : [MASK] pm every day. 570 [MASK] You want it, we have it. [SEP] [CLS] Then [MASK] can have a 10. [MASK] dinner with your family on Christmas Day [MASK] [SEP] [CLS] Each nation has many good people who help to take [MASK] of others [MASK] For example, some high school [MASK] college students in the USA often spend many hours as volunteers'\n"
          ]
        }
      ],
      "source": [
        "samples = [lm_datasets[\"train\"][i] for i in range(2)]\n",
        "for sample in samples:\n",
        "    _ = sample.pop(\"word_ids\")\n",
        "\n",
        "for chunk in data_collator(samples)[\"input_ids\"]:\n",
        "    print(f\"\\n'>>> {tokenizer.decode(chunk)}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJIpLTJB5fDo",
        "outputId": "85bdcaaa-1fe1-4c35-de4a-2432cc4ecc00"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': [119,\n",
              "  2563,\n",
              "  1176,\n",
              "  14249,\n",
              "  1272,\n",
              "  1104,\n",
              "  1160,\n",
              "  3672,\n",
              "  119,\n",
              "  102,\n",
              "  101,\n",
              "  8790,\n",
              "  4419,\n",
              "  1674,\n",
              "  183,\n",
              "  112,\n",
              "  189,\n",
              "  2616,\n",
              "  1234,\n",
              "  1277,\n",
              "  1948,\n",
              "  119,\n",
              "  138,\n",
              "  1363,\n",
              "  3111,\n",
              "  1104,\n",
              "  14249,\n",
              "  10909,\n",
              "  1105,\n",
              "  1199,\n",
              "  6062,\n",
              "  3459,\n",
              "  1132,\n",
              "  1536,\n",
              "  119,\n",
              "  102,\n",
              "  101,\n",
              "  2091,\n",
              "  1128,\n",
              "  1176,\n",
              "  2865,\n",
              "  1105,\n",
              "  1638,\n",
              "  136,\n",
              "  2408,\n",
              "  2126,\n",
              "  1107,\n",
              "  20272,\n",
              "  1202,\n",
              "  1136,\n",
              "  1138,\n",
              "  1277,\n",
              "  2000,\n",
              "  1111,\n",
              "  1638,\n",
              "  117,\n",
              "  1133,\n",
              "  1103,\n",
              "  1651,\n",
              "  1253,\n",
              "  1202,\n",
              "  2865,\n",
              "  119,\n",
              "  102,\n",
              "  101,\n",
              "  2408,\n",
              "  2126,\n",
              "  1107,\n",
              "  20272,\n",
              "  1202,\n",
              "  1136,\n",
              "  1138,\n",
              "  1277,\n",
              "  2000,\n",
              "  1111,\n",
              "  1638,\n",
              "  117,\n",
              "  1133,\n",
              "  1103,\n",
              "  1651,\n",
              "  1253,\n",
              "  1202,\n",
              "  2865,\n",
              "  119,\n",
              "  1636,\n",
              "  2126,\n",
              "  1510,\n",
              "  1138,\n",
              "  153,\n",
              "  2036,\n",
              "  8497,\n",
              "  117,\n",
              "  1719,\n",
              "  1113,\n",
              "  1103,\n",
              "  18514,\n",
              "  1137,\n",
              "  1113,\n",
              "  1103,\n",
              "  19507,\n",
              "  1104,\n",
              "  1103,\n",
              "  2275,\n",
              "  2809,\n",
              "  170,\n",
              "  1374,\n",
              "  2126,\n",
              "  1138,\n",
              "  1147,\n",
              "  1773,\n",
              "  3872,\n",
              "  1111,\n",
              "  1651,\n",
              "  119,\n",
              "  102,\n",
              "  101,\n",
              "  2408,\n",
              "  2126,\n",
              "  1107,\n",
              "  20272,\n",
              "  1202,\n",
              "  1136,\n",
              "  1138,\n",
              "  1277,\n",
              "  2000,\n",
              "  1111,\n",
              "  1638,\n",
              "  117],\n",
              " 'token_type_ids': [0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0],\n",
              " 'attention_mask': [1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1],\n",
              " 'word_ids': [34,\n",
              "  35,\n",
              "  36,\n",
              "  37,\n",
              "  38,\n",
              "  39,\n",
              "  40,\n",
              "  41,\n",
              "  42,\n",
              "  None,\n",
              "  None,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  3,\n",
              "  4,\n",
              "  5,\n",
              "  6,\n",
              "  7,\n",
              "  8,\n",
              "  9,\n",
              "  10,\n",
              "  11,\n",
              "  12,\n",
              "  13,\n",
              "  14,\n",
              "  15,\n",
              "  16,\n",
              "  17,\n",
              "  18,\n",
              "  19,\n",
              "  20,\n",
              "  21,\n",
              "  22,\n",
              "  None,\n",
              "  None,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  3,\n",
              "  4,\n",
              "  5,\n",
              "  6,\n",
              "  7,\n",
              "  8,\n",
              "  9,\n",
              "  10,\n",
              "  11,\n",
              "  12,\n",
              "  13,\n",
              "  14,\n",
              "  15,\n",
              "  16,\n",
              "  17,\n",
              "  18,\n",
              "  19,\n",
              "  20,\n",
              "  21,\n",
              "  22,\n",
              "  23,\n",
              "  24,\n",
              "  25,\n",
              "  None,\n",
              "  None,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  3,\n",
              "  4,\n",
              "  5,\n",
              "  6,\n",
              "  7,\n",
              "  8,\n",
              "  9,\n",
              "  10,\n",
              "  11,\n",
              "  12,\n",
              "  13,\n",
              "  14,\n",
              "  15,\n",
              "  16,\n",
              "  17,\n",
              "  18,\n",
              "  19,\n",
              "  20,\n",
              "  21,\n",
              "  22,\n",
              "  23,\n",
              "  23,\n",
              "  24,\n",
              "  25,\n",
              "  26,\n",
              "  27,\n",
              "  28,\n",
              "  29,\n",
              "  30,\n",
              "  31,\n",
              "  32,\n",
              "  33,\n",
              "  34,\n",
              "  35,\n",
              "  36,\n",
              "  37,\n",
              "  38,\n",
              "  39,\n",
              "  40,\n",
              "  41,\n",
              "  42,\n",
              "  43,\n",
              "  44,\n",
              "  45,\n",
              "  46,\n",
              "  47,\n",
              "  None,\n",
              "  None,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  3,\n",
              "  4,\n",
              "  5,\n",
              "  6,\n",
              "  7,\n",
              "  8,\n",
              "  9,\n",
              "  10,\n",
              "  11],\n",
              " 'labels': [119,\n",
              "  2563,\n",
              "  1176,\n",
              "  14249,\n",
              "  1272,\n",
              "  1104,\n",
              "  1160,\n",
              "  3672,\n",
              "  119,\n",
              "  102,\n",
              "  101,\n",
              "  8790,\n",
              "  4419,\n",
              "  1674,\n",
              "  183,\n",
              "  112,\n",
              "  189,\n",
              "  2616,\n",
              "  1234,\n",
              "  1277,\n",
              "  1948,\n",
              "  119,\n",
              "  138,\n",
              "  1363,\n",
              "  3111,\n",
              "  1104,\n",
              "  14249,\n",
              "  10909,\n",
              "  1105,\n",
              "  1199,\n",
              "  6062,\n",
              "  3459,\n",
              "  1132,\n",
              "  1536,\n",
              "  119,\n",
              "  102,\n",
              "  101,\n",
              "  2091,\n",
              "  1128,\n",
              "  1176,\n",
              "  2865,\n",
              "  1105,\n",
              "  1638,\n",
              "  136,\n",
              "  2408,\n",
              "  2126,\n",
              "  1107,\n",
              "  20272,\n",
              "  1202,\n",
              "  1136,\n",
              "  1138,\n",
              "  1277,\n",
              "  2000,\n",
              "  1111,\n",
              "  1638,\n",
              "  117,\n",
              "  1133,\n",
              "  1103,\n",
              "  1651,\n",
              "  1253,\n",
              "  1202,\n",
              "  2865,\n",
              "  119,\n",
              "  102,\n",
              "  101,\n",
              "  2408,\n",
              "  2126,\n",
              "  1107,\n",
              "  20272,\n",
              "  1202,\n",
              "  1136,\n",
              "  1138,\n",
              "  1277,\n",
              "  2000,\n",
              "  1111,\n",
              "  1638,\n",
              "  117,\n",
              "  1133,\n",
              "  1103,\n",
              "  1651,\n",
              "  1253,\n",
              "  1202,\n",
              "  2865,\n",
              "  119,\n",
              "  1636,\n",
              "  2126,\n",
              "  1510,\n",
              "  1138,\n",
              "  153,\n",
              "  2036,\n",
              "  8497,\n",
              "  117,\n",
              "  1719,\n",
              "  1113,\n",
              "  1103,\n",
              "  18514,\n",
              "  1137,\n",
              "  1113,\n",
              "  1103,\n",
              "  19507,\n",
              "  1104,\n",
              "  1103,\n",
              "  2275,\n",
              "  2809,\n",
              "  170,\n",
              "  1374,\n",
              "  2126,\n",
              "  1138,\n",
              "  1147,\n",
              "  1773,\n",
              "  3872,\n",
              "  1111,\n",
              "  1651,\n",
              "  119,\n",
              "  102,\n",
              "  101,\n",
              "  2408,\n",
              "  2126,\n",
              "  1107,\n",
              "  20272,\n",
              "  1202,\n",
              "  1136,\n",
              "  1138,\n",
              "  1277,\n",
              "  2000,\n",
              "  1111,\n",
              "  1638,\n",
              "  117]}"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_size = 100\n",
        "test_size = int(0.1 * train_size)\n",
        "\n",
        "downsampled_dataset = lm_datasets[\"train\"].train_test_split(\n",
        "    train_size=train_size, test_size=test_size, seed=42\n",
        ")\n",
        "downsampled_dataset[\"train\"][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJHvVPoWcb3W"
      },
      "source": [
        "# Trainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Iz8s3W_bW9s"
      },
      "source": [
        "# CustomTrainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQJBdEGQimpu"
      },
      "outputs": [],
      "source": [
        "# coding=utf-8\n",
        "# Copyright 2020-present the HuggingFace Inc. team.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\"\"\"\n",
        "The Trainer class, to easily train a  Transformers from scratch or finetune it on a new task.\n",
        "\"\"\"\n",
        "\n",
        "import contextlib\n",
        "import copy\n",
        "import functools\n",
        "import glob\n",
        "import importlib.metadata\n",
        "import inspect\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import re\n",
        "import shutil\n",
        "import sys\n",
        "import time\n",
        "import warnings\n",
        "from collections.abc import Mapping\n",
        "from pathlib import Path\n",
        "from typing import TYPE_CHECKING, Any, Callable, Dict, List, Optional, Tuple, Union\n",
        "\n",
        "\n",
        "# Integrations must be imported before ML frameworks:\n",
        "# isort: off\n",
        "from transformers.integrations import (\n",
        "    get_reporting_integration_callbacks,\n",
        "    hp_params,\n",
        ")\n",
        "\n",
        "# isort: on\n",
        "\n",
        "import huggingface_hub.utils as hf_hub_utils\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.distributed as dist\n",
        "from huggingface_hub import Repository, create_repo, upload_folder\n",
        "from packaging import version\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler\n",
        "\n",
        "from transformers import __version__\n",
        "from transformers.configuration_utils import PretrainedConfig\n",
        "from transformers.data.data_collator import DataCollator, DataCollatorWithPadding, default_data_collator\n",
        "from transformers.debug_utils import DebugOption, DebugUnderflowOverflow\n",
        "from transformers.hyperparameter_search import ALL_HYPERPARAMETER_SEARCH_BACKENDS, default_hp_search_backend\n",
        "from transformers.integrations.deepspeed import deepspeed_init, deepspeed_load_checkpoint, is_deepspeed_available\n",
        "from transformers.modelcard import TrainingSummary\n",
        "from transformers.modeling_utils import PreTrainedModel, load_sharded_checkpoint, unwrap_model\n",
        "from transformers.models.auto.modeling_auto import MODEL_FOR_CAUSAL_LM_MAPPING_NAMES, MODEL_MAPPING_NAMES\n",
        "from transformers.optimization import Adafactor, get_scheduler\n",
        "from transformers.pytorch_utils import ALL_LAYERNORM_LAYERS, is_torch_less_than_1_11\n",
        "from transformers.tokenization_utils_base import PreTrainedTokenizerBase\n",
        "from transformers.trainer_callback import (\n",
        "    CallbackHandler,\n",
        "    DefaultFlowCallback,\n",
        "    PrinterCallback,\n",
        "    ProgressCallback,\n",
        "    TrainerCallback,\n",
        "    TrainerControl,\n",
        "    TrainerState,\n",
        ")\n",
        "from transformers.trainer_pt_utils import (\n",
        "    DistributedTensorGatherer,\n",
        "    IterableDatasetShard,\n",
        "    LabelSmoother,\n",
        "    LengthGroupedSampler,\n",
        "    SequentialDistributedSampler,\n",
        "    distributed_broadcast_scalars,\n",
        "    distributed_concat,\n",
        "    find_batch_size,\n",
        "    get_dataloader_sampler,\n",
        "    get_model_param_count,\n",
        "    get_module_class_from_name,\n",
        "    get_parameter_names,\n",
        "    nested_concat,\n",
        "    nested_detach,\n",
        "    nested_numpify,\n",
        "    nested_xla_mesh_reduce,\n",
        "    reissue_pt_warnings,\n",
        "    remove_dummy_checkpoint,\n",
        ")\n",
        "from transformers.trainer_utils import (\n",
        "    PREFIX_CHECKPOINT_DIR,\n",
        "    BestRun,\n",
        "    EvalLoopOutput,\n",
        "    EvalPrediction,\n",
        "    FSDPOption,\n",
        "    HPSearchBackend,\n",
        "    HubStrategy,\n",
        "    IntervalStrategy,\n",
        "    PredictionOutput,\n",
        "    RemoveColumnsCollator,\n",
        "    TrainerMemoryTracker,\n",
        "    TrainOutput,\n",
        "    default_compute_objective,\n",
        "    denumpify_detensorize,\n",
        "    enable_full_determinism,\n",
        "    find_executable_batch_size,\n",
        "    get_last_checkpoint,\n",
        "    has_length,\n",
        "    number_of_arguments,\n",
        "    seed_worker,\n",
        "    set_seed,\n",
        "    speed_metrics,\n",
        ")\n",
        "from transformers.training_args import OptimizerNames, ParallelMode, TrainingArguments\n",
        "from transformers.utils import (\n",
        "    ADAPTER_CONFIG_NAME,\n",
        "    ADAPTER_SAFE_WEIGHTS_NAME,\n",
        "    ADAPTER_WEIGHTS_NAME,\n",
        "    CONFIG_NAME,\n",
        "    SAFE_WEIGHTS_INDEX_NAME,\n",
        "    SAFE_WEIGHTS_NAME,\n",
        "    WEIGHTS_INDEX_NAME,\n",
        "    WEIGHTS_NAME,\n",
        "    PushInProgress,\n",
        "    can_return_loss,\n",
        "    find_labels,\n",
        "    is_accelerate_available,\n",
        "    is_apex_available,\n",
        "    is_bitsandbytes_available,\n",
        "    is_datasets_available,\n",
        "    is_in_notebook,\n",
        "    is_ipex_available,\n",
        "    is_peft_available,\n",
        "    is_safetensors_available,\n",
        "    is_sagemaker_dp_enabled,\n",
        "    is_sagemaker_mp_enabled,\n",
        "    is_torch_compile_available,\n",
        "    is_torch_neuroncore_available,\n",
        "    is_torch_tpu_available,\n",
        "    logging,\n",
        "    strtobool,\n",
        ")\n",
        "from transformers.utils.quantization_config import QuantizationMethod\n",
        "\n",
        "\n",
        "DEFAULT_CALLBACKS = [DefaultFlowCallback]\n",
        "DEFAULT_PROGRESS_CALLBACK = ProgressCallback\n",
        "\n",
        "if is_in_notebook():\n",
        "    from transformers.utils.notebook import NotebookProgressCallback\n",
        "\n",
        "    DEFAULT_PROGRESS_CALLBACK = NotebookProgressCallback\n",
        "\n",
        "if is_apex_available():\n",
        "    from apex import amp\n",
        "\n",
        "if is_datasets_available():\n",
        "    import datasets\n",
        "\n",
        "if is_torch_tpu_available(check_device=False):\n",
        "    import torch_xla.core.xla_model as xm\n",
        "    import torch_xla.debug.metrics as met\n",
        "\n",
        "\n",
        "if is_sagemaker_mp_enabled():\n",
        "    import smdistributed.modelparallel.torch as smp\n",
        "    from smdistributed.modelparallel import __version__ as SMP_VERSION\n",
        "\n",
        "    IS_SAGEMAKER_MP_POST_1_10 = version.parse(SMP_VERSION) >= version.parse(\"1.10\")\n",
        "\n",
        "    from transformers.trainer_pt_utils import smp_forward_backward, smp_forward_only, smp_gather, smp_nested_concat\n",
        "else:\n",
        "    IS_SAGEMAKER_MP_POST_1_10 = False\n",
        "\n",
        "\n",
        "if is_safetensors_available():\n",
        "    import safetensors.torch\n",
        "\n",
        "\n",
        "if is_peft_available():\n",
        "    from peft import PeftModel\n",
        "\n",
        "\n",
        "if is_accelerate_available():\n",
        "    from accelerate import Accelerator, skip_first_batches\n",
        "    from accelerate import __version__ as accelerate_version\n",
        "    from accelerate.utils import DistributedDataParallelKwargs, GradientAccumulationPlugin\n",
        "\n",
        "    if version.parse(accelerate_version) > version.parse(\"0.20.3\"):\n",
        "        from accelerate.utils import (\n",
        "            load_fsdp_model,\n",
        "            load_fsdp_optimizer,\n",
        "            save_fsdp_model,\n",
        "            save_fsdp_optimizer,\n",
        "        )\n",
        "\n",
        "    if is_deepspeed_available():\n",
        "        from accelerate.utils import DeepSpeedSchedulerWrapper\n",
        "\n",
        "\n",
        "if TYPE_CHECKING:\n",
        "    import optuna\n",
        "\n",
        "\n",
        "logger = logging.get_logger(__name__)\n",
        "\n",
        "\n",
        "# Name of the files used for checkpointing\n",
        "TRAINING_ARGS_NAME = \"training_args.bin\"\n",
        "TRAINER_STATE_NAME = \"trainer_state.json\"\n",
        "OPTIMIZER_NAME = \"optimizer.pt\"\n",
        "OPTIMIZER_NAME_BIN = \"optimizer.bin\"\n",
        "SCHEDULER_NAME = \"scheduler.pt\"\n",
        "SCALER_NAME = \"scaler.pt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0gZDnDUbOv5"
      },
      "outputs": [],
      "source": [
        "class CustomTrainer(Trainer):\n",
        "    def _inner_training_loop(\n",
        "        self, batch_size=None, args=None, resume_from_checkpoint=None, trial=None, ignore_keys_for_eval=None\n",
        "    ):\n",
        "        self.accelerator.free_memory()\n",
        "        self._train_batch_size = batch_size\n",
        "        logger.debug(f\"Currently training with a batch size of: {self._train_batch_size}\")\n",
        "        # Data loader and number of training steps\n",
        "        train_dataloader = self.get_train_dataloader()\n",
        "\n",
        "        # Setting up training control variables:\n",
        "        # number of training epochs: num_train_epochs\n",
        "        # number of training steps per epoch: num_update_steps_per_epoch\n",
        "        # total number of training steps to execute: max_steps\n",
        "        total_train_batch_size = self._train_batch_size * args.gradient_accumulation_steps * args.world_size\n",
        "\n",
        "        len_dataloader = None\n",
        "        num_train_tokens = None\n",
        "        if has_length(train_dataloader):\n",
        "            len_dataloader = len(train_dataloader)\n",
        "            num_update_steps_per_epoch = len_dataloader // args.gradient_accumulation_steps\n",
        "            num_update_steps_per_epoch = max(num_update_steps_per_epoch, 1)\n",
        "            num_examples = self.num_examples(train_dataloader)\n",
        "            if args.max_steps > 0:\n",
        "                max_steps = args.max_steps\n",
        "                num_train_epochs = args.max_steps // num_update_steps_per_epoch + int(\n",
        "                    args.max_steps % num_update_steps_per_epoch > 0\n",
        "                )\n",
        "                # May be slightly incorrect if the last batch in the training dataloader has a smaller size but it's\n",
        "                # the best we can do.\n",
        "                num_train_samples = args.max_steps * total_train_batch_size\n",
        "                if args.include_tokens_per_second:\n",
        "                    num_train_tokens = (\n",
        "                        self.num_tokens(train_dataloader, args.max_steps) * args.gradient_accumulation_steps\n",
        "                    )\n",
        "            else:\n",
        "                max_steps = math.ceil(args.num_train_epochs * num_update_steps_per_epoch)\n",
        "                num_train_epochs = math.ceil(args.num_train_epochs)\n",
        "                num_train_samples = self.num_examples(train_dataloader) * args.num_train_epochs\n",
        "                if args.include_tokens_per_second:\n",
        "                    num_train_tokens = self.num_tokens(train_dataloader) * args.num_train_epochs\n",
        "        elif args.max_steps > 0:  # Rely on max_steps when dataloader does not have a working size\n",
        "            max_steps = args.max_steps\n",
        "            # Setting a very large number of epochs so we go as many times as necessary over the iterator.\n",
        "            num_train_epochs = sys.maxsize\n",
        "            num_update_steps_per_epoch = max_steps\n",
        "            num_examples = total_train_batch_size * args.max_steps\n",
        "            num_train_samples = args.max_steps * total_train_batch_size\n",
        "            if args.include_tokens_per_second:\n",
        "                num_train_tokens = self.num_tokens(train_dataloader, args.max_steps) * args.gradient_accumulation_steps\n",
        "        else:\n",
        "            raise ValueError(\n",
        "                \"args.max_steps must be set to a positive value if dataloader does not have a length, was\"\n",
        "                f\" {args.max_steps}\"\n",
        "            )\n",
        "\n",
        "        if DebugOption.UNDERFLOW_OVERFLOW in self.args.debug:\n",
        "            if self.args.n_gpu > 1:\n",
        "                # nn.DataParallel(model) replicates the model, creating new variables and module\n",
        "                # references registered here no longer work on other gpus, breaking the module\n",
        "                raise ValueError(\n",
        "                    \"Currently --debug underflow_overflow is not supported under DP. Please use DDP\"\n",
        "                    \" (torch.distributed.launch).\"\n",
        "                )\n",
        "            else:\n",
        "                debug_overflow = DebugUnderflowOverflow(self.model)  # noqa\n",
        "\n",
        "        delay_optimizer_creation = is_sagemaker_mp_enabled() or self.fsdp is not None or self.is_fsdp_enabled\n",
        "\n",
        "        # We need to reset the scheduler, as its parameters may be different on subsequent calls\n",
        "        if self._created_lr_scheduler:\n",
        "            self.lr_scheduler = None\n",
        "            self._created_lr_scheduler = False\n",
        "\n",
        "        if self.is_deepspeed_enabled:\n",
        "            self.optimizer, self.lr_scheduler = deepspeed_init(self, num_training_steps=max_steps)\n",
        "\n",
        "        if not delay_optimizer_creation:\n",
        "            self.create_optimizer_and_scheduler(num_training_steps=max_steps)\n",
        "\n",
        "        self.state = TrainerState()\n",
        "        self.state.is_hyper_param_search = trial is not None\n",
        "\n",
        "        # Compute absolute values for logging, eval, and save if given as ratio\n",
        "        if args.logging_steps is not None:\n",
        "            if args.logging_steps < 1:\n",
        "                self.state.logging_steps = math.ceil(max_steps * args.logging_steps)\n",
        "            else:\n",
        "                self.state.logging_steps = args.logging_steps\n",
        "        if args.eval_steps is not None:\n",
        "            if args.eval_steps < 1:\n",
        "                self.state.eval_steps = math.ceil(max_steps * args.eval_steps)\n",
        "            else:\n",
        "                self.state.eval_steps = args.eval_steps\n",
        "        if args.save_steps is not None:\n",
        "            if args.save_steps < 1:\n",
        "                self.state.save_steps = math.ceil(max_steps * args.save_steps)\n",
        "            else:\n",
        "                self.state.save_steps = args.save_steps\n",
        "\n",
        "        # Activate gradient checkpointing if needed\n",
        "        if args.gradient_checkpointing:\n",
        "            self.model.gradient_checkpointing_enable()\n",
        "\n",
        "        model = self._wrap_model(self.model_wrapped)\n",
        "\n",
        "        # as the model is wrapped, don't use `accelerator.prepare`\n",
        "        # this is for unhandled cases such as\n",
        "        # FSDP-XLA, SageMaker MP/DP, DataParallel, IPEX\n",
        "        use_accelerator_prepare = True if model is self.model else False\n",
        "\n",
        "        if delay_optimizer_creation:\n",
        "            if use_accelerator_prepare:\n",
        "                self.model = self.accelerator.prepare(self.model)\n",
        "            self.create_optimizer_and_scheduler(num_training_steps=max_steps)\n",
        "\n",
        "        # prepare using `accelerator` prepare\n",
        "        if use_accelerator_prepare:\n",
        "            self.model.train()\n",
        "            if hasattr(self.lr_scheduler, \"step\"):\n",
        "                if self.use_apex:\n",
        "                    model = self.accelerator.prepare(self.model)\n",
        "                else:\n",
        "                    model, self.optimizer = self.accelerator.prepare(self.model, self.optimizer)\n",
        "            else:\n",
        "                # to handle cases wherein we pass \"DummyScheduler\" such as when it is specified in DeepSpeed config.\n",
        "                model, self.optimizer, self.lr_scheduler = self.accelerator.prepare(\n",
        "                    self.model, self.optimizer, self.lr_scheduler\n",
        "                )\n",
        "\n",
        "        if self.is_fsdp_enabled:\n",
        "            self.model = self.model_wrapped = model\n",
        "\n",
        "        # for the rest of this function `model` is the outside model, whether it was wrapped or not\n",
        "        if model is not self.model:\n",
        "            self.model_wrapped = model\n",
        "\n",
        "        # backward compatibility\n",
        "        if self.is_deepspeed_enabled:\n",
        "            self.deepspeed = self.model_wrapped\n",
        "\n",
        "        # ckpt loading\n",
        "        if resume_from_checkpoint is not None:\n",
        "            if self.is_deepspeed_enabled:\n",
        "                deepspeed_load_checkpoint(self.model_wrapped, resume_from_checkpoint)\n",
        "            elif is_sagemaker_mp_enabled() or self.is_fsdp_enabled:\n",
        "                self._load_from_checkpoint(resume_from_checkpoint, self.model_wrapped)\n",
        "\n",
        "        # Check if saved optimizer or scheduler states exist\n",
        "        self._load_optimizer_and_scheduler(resume_from_checkpoint)\n",
        "\n",
        "        # important: at this point:\n",
        "        # self.model         is the Transformers Model\n",
        "        # self.model_wrapped is DDP(Transformers Model), Deepspeed(Transformers Model),\n",
        "        # FSDP(Transformers Model), Dynamo Optimized Module(Transformers Model) etc.\n",
        "\n",
        "        # Train!\n",
        "        logger.info(\"***** Running training *****\")\n",
        "        logger.info(f\"  Num examples = {num_examples:,}\")\n",
        "        logger.info(f\"  Num Epochs = {num_train_epochs:,}\")\n",
        "        logger.info(f\"  Instantaneous batch size per device = {self.args.per_device_train_batch_size:,}\")\n",
        "        if self.args.per_device_train_batch_size != self._train_batch_size:\n",
        "            logger.info(f\"  Training with DataParallel so batch size has been adjusted to: {self._train_batch_size:,}\")\n",
        "        logger.info(f\"  Total train batch size (w. parallel, distributed & accumulation) = {total_train_batch_size:,}\")\n",
        "        logger.info(f\"  Gradient Accumulation steps = {args.gradient_accumulation_steps}\")\n",
        "        logger.info(f\"  Total optimization steps = {max_steps:,}\")\n",
        "        logger.info(f\"  Number of trainable parameters = {get_model_param_count(model, trainable_only=True):,}\")\n",
        "\n",
        "        self.state.epoch = 0\n",
        "        start_time = time.time()\n",
        "        epochs_trained = 0\n",
        "        steps_trained_in_current_epoch = 0\n",
        "        steps_trained_progress_bar = None\n",
        "\n",
        "        # Check if continuing training from a checkpoint\n",
        "        if resume_from_checkpoint is not None and os.path.isfile(\n",
        "            os.path.join(resume_from_checkpoint, TRAINER_STATE_NAME)\n",
        "        ):\n",
        "            self.state = TrainerState.load_from_json(os.path.join(resume_from_checkpoint, TRAINER_STATE_NAME))\n",
        "            epochs_trained = self.state.global_step // num_update_steps_per_epoch\n",
        "            if not args.ignore_data_skip:\n",
        "                steps_trained_in_current_epoch = self.state.global_step % (num_update_steps_per_epoch)\n",
        "                steps_trained_in_current_epoch *= args.gradient_accumulation_steps\n",
        "            else:\n",
        "                steps_trained_in_current_epoch = 0\n",
        "\n",
        "            logger.info(\"  Continuing training from checkpoint, will skip to saved global_step\")\n",
        "            logger.info(f\"  Continuing training from epoch {epochs_trained}\")\n",
        "            logger.info(f\"  Continuing training from global step {self.state.global_step}\")\n",
        "            if not args.ignore_data_skip:\n",
        "                logger.info(\n",
        "                    f\"  Will skip the first {epochs_trained} epochs then the first\"\n",
        "                    f\" {steps_trained_in_current_epoch} batches in the first epoch.\"\n",
        "                )\n",
        "\n",
        "        # Update the references\n",
        "        self.callback_handler.model = self.model\n",
        "        self.callback_handler.optimizer = self.optimizer\n",
        "        self.callback_handler.lr_scheduler = self.lr_scheduler\n",
        "        self.callback_handler.train_dataloader = train_dataloader\n",
        "        if self.hp_name is not None and self._trial is not None:\n",
        "            # use self._trial because the SigOpt/Optuna hpo only call `_hp_search_setup(trial)` instead of passing trial\n",
        "            # parameter to Train when using DDP.\n",
        "            self.state.trial_name = self.hp_name(self._trial)\n",
        "        if trial is not None:\n",
        "            assignments = trial.assignments if self.hp_search_backend == HPSearchBackend.SIGOPT else trial\n",
        "            self.state.trial_params = hp_params(assignments)\n",
        "        else:\n",
        "            self.state.trial_params = None\n",
        "        # This should be the same if the state has been saved but in case the training arguments changed, it's safer\n",
        "        # to set this after the load.\n",
        "        self.state.max_steps = max_steps\n",
        "        self.state.num_train_epochs = num_train_epochs\n",
        "        self.state.is_local_process_zero = self.is_local_process_zero()\n",
        "        self.state.is_world_process_zero = self.is_world_process_zero()\n",
        "\n",
        "        # tr_loss is a tensor to avoid synchronization of TPUs through .item()\n",
        "        tr_loss = torch.tensor(0.0).to(args.device)\n",
        "        # _total_loss_scalar is updated everytime .item() has to be called on tr_loss and stores the sum of all losses\n",
        "        self._total_loss_scalar = 0.0\n",
        "        self._globalstep_last_logged = self.state.global_step\n",
        "        model.zero_grad()\n",
        "\n",
        "        self.control = self.callback_handler.on_train_begin(args, self.state, self.control)\n",
        "\n",
        "        # Skip the first epochs_trained epochs to get the random state of the dataloader at the right point.\n",
        "        if not args.ignore_data_skip:\n",
        "            for epoch in range(epochs_trained):\n",
        "                sampler = get_dataloader_sampler(train_dataloader)\n",
        "                is_random_sampler = isinstance(sampler, RandomSampler)\n",
        "                if is_torch_less_than_1_11 or not is_random_sampler:\n",
        "                    # We just need to begin an iteration to create the randomization of the sampler.\n",
        "                    for _ in train_dataloader:\n",
        "                        break\n",
        "                else:\n",
        "                    # Otherwise we need to call the whooooole sampler cause there is some random operation added\n",
        "                    # AT THE VERY END!\n",
        "                    sampler = sampler if sampler is not None else []\n",
        "                    _ = list(sampler)\n",
        "\n",
        "        total_batched_samples = 0\n",
        "        for epoch in range(epochs_trained, num_train_epochs):\n",
        "            epoch_iterator = train_dataloader\n",
        "\n",
        "            # Reset the past mems state at the beginning of each epoch if necessary.\n",
        "            if args.past_index >= 0:\n",
        "                self._past = None\n",
        "\n",
        "            steps_in_epoch = (\n",
        "                len(epoch_iterator)\n",
        "                if len_dataloader is not None\n",
        "                else args.max_steps * args.gradient_accumulation_steps\n",
        "            )\n",
        "            self.control = self.callback_handler.on_epoch_begin(args, self.state, self.control)\n",
        "\n",
        "            if epoch == epochs_trained and resume_from_checkpoint is not None and steps_trained_in_current_epoch == 0:\n",
        "                self._load_rng_state(resume_from_checkpoint)\n",
        "\n",
        "            rng_to_sync = False\n",
        "            steps_skipped = 0\n",
        "            if steps_trained_in_current_epoch > 0:\n",
        "                epoch_iterator = skip_first_batches(epoch_iterator, steps_trained_in_current_epoch)\n",
        "                steps_skipped = steps_trained_in_current_epoch\n",
        "                steps_trained_in_current_epoch = 0\n",
        "                rng_to_sync = True\n",
        "\n",
        "            step = -1\n",
        "            for step, inputs in enumerate(epoch_iterator):\n",
        "                entropy = 0\n",
        "                total_batched_samples += 1\n",
        "                if rng_to_sync:\n",
        "                    self._load_rng_state(resume_from_checkpoint)\n",
        "                    rng_to_sync = False\n",
        "\n",
        "                # Skip past any already trained steps if resuming training\n",
        "                if steps_trained_in_current_epoch > 0:\n",
        "                    steps_trained_in_current_epoch -= 1\n",
        "                    if steps_trained_progress_bar is not None:\n",
        "                        steps_trained_progress_bar.update(1)\n",
        "                    if steps_trained_in_current_epoch == 0:\n",
        "                        self._load_rng_state(resume_from_checkpoint)\n",
        "                    continue\n",
        "                elif steps_trained_progress_bar is not None:\n",
        "                    steps_trained_progress_bar.close()\n",
        "                    steps_trained_progress_bar = None\n",
        "\n",
        "                if step % args.gradient_accumulation_steps == 0:\n",
        "                    self.control = self.callback_handler.on_step_begin(args, self.state, self.control)\n",
        "\n",
        "                with self.accelerator.accumulate(model):\n",
        "                    tr_loss_step = self.training_step(model, inputs)\n",
        "\n",
        "                if (\n",
        "                    args.logging_nan_inf_filter\n",
        "                    and not is_torch_tpu_available()\n",
        "                    and (torch.isnan(tr_loss_step) or torch.isinf(tr_loss_step))\n",
        "                ):\n",
        "                    # if loss is nan or inf simply add the average of previous logged losses\n",
        "                    tr_loss += tr_loss / (1 + self.state.global_step - self._globalstep_last_logged)\n",
        "                else:\n",
        "                    tr_loss += tr_loss_step\n",
        "\n",
        "                self.current_flos += float(self.floating_point_ops(inputs))\n",
        "\n",
        "                is_last_step_and_steps_less_than_grad_acc = (\n",
        "                    steps_in_epoch <= args.gradient_accumulation_steps and (step + 1) == steps_in_epoch\n",
        "                )\n",
        "\n",
        "                if (\n",
        "                    total_batched_samples % args.gradient_accumulation_steps == 0\n",
        "                    or\n",
        "                    # last step in epoch but step is always smaller than gradient_accumulation_steps\n",
        "                    is_last_step_and_steps_less_than_grad_acc\n",
        "                ):\n",
        "                    # the `or` condition of `is_last_step_and_steps_less_than_grad_acc` is not covered\n",
        "                    # in accelerate. So, explicitly enable sync gradients to True in that case.\n",
        "                    if is_last_step_and_steps_less_than_grad_acc or (\n",
        "                        version.parse(accelerate_version) <= version.parse(\"0.20.3\")\n",
        "                    ):\n",
        "                        self.accelerator.gradient_state._set_sync_gradients(True)\n",
        "\n",
        "                    # Gradient clipping\n",
        "                    if args.max_grad_norm is not None and args.max_grad_norm > 0:\n",
        "                        # deepspeed does its own clipping\n",
        "\n",
        "                        if is_sagemaker_mp_enabled() and args.fp16:\n",
        "                            self.optimizer.clip_master_grads(args.max_grad_norm)\n",
        "                        elif hasattr(self.optimizer, \"clip_grad_norm\"):\n",
        "                            # Some optimizers (like the sharded optimizer) have a specific way to do gradient clipping\n",
        "                            self.optimizer.clip_grad_norm(args.max_grad_norm)\n",
        "                        elif hasattr(model, \"clip_grad_norm_\"):\n",
        "                            # Some models (like FullyShardedDDP) have a specific way to do gradient clipping\n",
        "                            model.clip_grad_norm_(args.max_grad_norm)\n",
        "                        elif self.use_apex:\n",
        "                            # Revert to normal clipping otherwise, handling Apex or full precision\n",
        "                            nn.utils.clip_grad_norm_(\n",
        "                                amp.master_params(self.optimizer),\n",
        "                                args.max_grad_norm,\n",
        "                            )\n",
        "                        else:\n",
        "                            self.accelerator.clip_grad_norm_(\n",
        "                                model.parameters(),\n",
        "                                args.max_grad_norm,\n",
        "                            )\n",
        "\n",
        "                    with torch.no_grad():\n",
        "                        logits = model(**inputs).logits\n",
        "\n",
        "                    mask_token_index = (inputs.input_ids == tokenizer.mask_token_id)[0].nonzero(as_tuple=True)[0]\n",
        "                    predicted_token_id = logits[0, mask_token_index].argmax(axis=-1)\n",
        "\n",
        "                    predicted_words = tokenizer.decode(predicted_token_id)\n",
        "                    label_words = tokenizer.decode(inputs[\"labels\"][0][mask_token_index])\n",
        "\n",
        "                    predicted_words_list = predicted_words.split()\n",
        "                    label_words_list = label_words.split()\n",
        "\n",
        "                    num_words = len(label_words_list)\n",
        "\n",
        "                    for i in range(num_words):\n",
        "                      if (i >= len(predicted_words_list)) or (i >= len(label_words_list)):\n",
        "                        break\n",
        "                      entropy += torch.sum(compute_loss(\"cross_entropy\",compare_with_semantic_differential(predicted_words_list[i]),compare_with_semantic_differential(label_words_list[i])))\n",
        "\n",
        "                    entropy = math.pow(entropy.item(), 1/4)\n",
        "                    print(entropy)\n",
        "\n",
        "                    for group in self.optimizer.param_groups:\n",
        "                        group[\"lr\"] /= entropy\n",
        "                        print(group[\"lr\"])\n",
        "\n",
        "                    # Optimizer step\n",
        "                    self.optimizer.step()\n",
        "                    optimizer_was_run = not self.accelerator.optimizer_step_was_skipped\n",
        "                    if optimizer_was_run:\n",
        "                        # Delay optimizer scheduling until metrics are generated\n",
        "                        if not isinstance(self.lr_scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
        "                            self.lr_scheduler.step()\n",
        "\n",
        "                    model.zero_grad()\n",
        "                    self.state.global_step += 1\n",
        "                    self.state.epoch = epoch + (step + 1 + steps_skipped) / steps_in_epoch\n",
        "                    self.control = self.callback_handler.on_step_end(args, self.state, self.control)\n",
        "\n",
        "                    self._maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_keys_for_eval)\n",
        "                else:\n",
        "                    self.control = self.callback_handler.on_substep_end(args, self.state, self.control)\n",
        "\n",
        "                if self.control.should_epoch_stop or self.control.should_training_stop:\n",
        "                    break\n",
        "            if step < 0:\n",
        "                logger.warning(\n",
        "                    \"There seems to be not a single sample in your epoch_iterator, stopping training at step\"\n",
        "                    f\" {self.state.global_step}! This is expected if you're using an IterableDataset and set\"\n",
        "                    f\" num_steps ({max_steps}) higher than the number of available samples.\"\n",
        "                )\n",
        "                self.control.should_training_stop = True\n",
        "\n",
        "            self.control = self.callback_handler.on_epoch_end(args, self.state, self.control)\n",
        "            self._maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_keys_for_eval)\n",
        "\n",
        "            if DebugOption.TPU_METRICS_DEBUG in self.args.debug:\n",
        "                if is_torch_tpu_available():\n",
        "                    # tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\n",
        "                    xm.master_print(met.metrics_report())\n",
        "                else:\n",
        "                    logger.warning(\n",
        "                        \"You enabled PyTorch/XLA debug metrics but you don't have a TPU \"\n",
        "                        \"configured. Check your training configuration if this is unexpected.\"\n",
        "                    )\n",
        "            if self.control.should_training_stop:\n",
        "                break\n",
        "\n",
        "        if args.past_index and hasattr(self, \"_past\"):\n",
        "            # Clean the state at the end of training\n",
        "            delattr(self, \"_past\")\n",
        "\n",
        "        logger.info(\"\\n\\nTraining completed. Do not forget to share your model on huggingface.co/models =)\\n\\n\")\n",
        "        if args.load_best_model_at_end and self.state.best_model_checkpoint is not None:\n",
        "            # Wait for everyone to get here so we are sur the model has been saved by process 0.\n",
        "            if is_torch_tpu_available():\n",
        "                xm.rendezvous(\"load_best_model_at_end\")\n",
        "            elif args.parallel_mode == ParallelMode.DISTRIBUTED:\n",
        "                dist.barrier()\n",
        "            elif is_sagemaker_mp_enabled():\n",
        "                smp.barrier()\n",
        "\n",
        "            self._load_best_model()\n",
        "\n",
        "        # add remaining tr_loss\n",
        "        self._total_loss_scalar += tr_loss.item()\n",
        "        train_loss = self._total_loss_scalar / self.state.global_step\n",
        "\n",
        "        metrics = speed_metrics(\n",
        "            \"train\",\n",
        "            start_time,\n",
        "            num_samples=num_train_samples,\n",
        "            num_steps=self.state.max_steps,\n",
        "            num_tokens=num_train_tokens,\n",
        "        )\n",
        "        self.store_flos()\n",
        "        metrics[\"total_flos\"] = self.state.total_flos\n",
        "        metrics[\"train_loss\"] = train_loss\n",
        "\n",
        "        self.is_in_train = False\n",
        "\n",
        "        self._memory_tracker.stop_and_update_metrics(metrics)\n",
        "\n",
        "        self.log(metrics)\n",
        "\n",
        "        run_dir = self._get_output_dir(trial)\n",
        "        checkpoints_sorted = self._sorted_checkpoints(use_mtime=False, output_dir=run_dir)\n",
        "\n",
        "        # Delete the last checkpoint when save_total_limit=1 if it's different from the best checkpoint and process allowed to save.\n",
        "        if self.args.should_save and self.state.best_model_checkpoint is not None and self.args.save_total_limit == 1:\n",
        "            for checkpoint in checkpoints_sorted:\n",
        "                if not os.path.samefile(checkpoint, self.state.best_model_checkpoint):\n",
        "                    logger.info(f\"Deleting older checkpoint [{checkpoint}] due to args.save_total_limit\")\n",
        "                    shutil.rmtree(checkpoint)\n",
        "\n",
        "        self.control = self.callback_handler.on_train_end(args, self.state, self.control)\n",
        "\n",
        "        # Wait for the checkpoint to be uploaded.\n",
        "        self._finish_current_push()\n",
        "\n",
        "        return TrainOutput(self.state.global_step, train_loss, metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6M88o6uvbcul"
      },
      "source": [
        "# Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1XsFEOaWcoz3"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "# Show the training loss with every epoch\n",
        "logging_steps = len(downsampled_dataset[\"train\"]) // batch_size\n",
        "model_name = model_checkpoint.split(\"/\")[-1]\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=f\"{model_name}-finetuned-imdb\",\n",
        "    overwrite_output_dir=True,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "    save_steps = 1000,\n",
        "    save_strategy = \"epoch\",\n",
        "    num_train_epochs=100,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    push_to_hub=False,\n",
        "    logging_steps=logging_steps,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VND_8w1T5jL2"
      },
      "outputs": [],
      "source": [
        "trainer = CustomTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=downsampled_dataset[\"train\"],\n",
        "    eval_dataset=downsampled_dataset[\"test\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "jxT6eGsppqRJ",
        "outputId": "7e8ee246-0bd3-4a62-818a-36ee732a4103"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.2250123106758504\n",
            "6.201526714733283e-06\n",
            "6.201526714733283e-06\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  7/200 00:20 < 13:25, 0.24 it/s, Epoch 3/100]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.643400</td>\n",
              "      <td>1.088714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.640500</td>\n",
              "      <td>1.818825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.558700</td>\n",
              "      <td>1.935174</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.458309800328016\n",
            "5.782815155229803e-06\n",
            "5.782815155229803e-06\n",
            "3.2596603491128673\n",
            "6.134094801962748e-06\n",
            "6.134094801962748e-06\n",
            "2.840324752044931\n",
            "7.0375398923057715e-06\n",
            "7.0375398923057715e-06\n",
            "3.6224482099949564\n",
            "5.515680591141022e-06\n",
            "5.515680591141022e-06\n",
            "3.2228485131159004\n",
            "6.196125339451582e-06\n",
            "6.196125339451582e-06\n"
          ]
        }
      ],
      "source": [
        "trainer.train()\n",
        "state = trainer.state.log_history\n",
        "print(state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GxJy0A6WlSdw"
      },
      "outputs": [],
      "source": [
        "torch.optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZQ5fdk5ARzv"
      },
      "outputs": [],
      "source": [
        "dir = \"/content/drive/MyDrive/data/SEEDS/ConstantWithNoSD.json\"\n",
        "\n",
        "with open(dir, mode=\"a\", encoding=\"utf-8\") as f:\n",
        "  json.dump(state, f, ensure_ascii=False, indent=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C70Tx9DzFQgq"
      },
      "outputs": [],
      "source": [
        "evals = [[],[]]\n",
        "train = [[],[]]\n",
        "\n",
        "for i, column in enumerate(state):\n",
        "    if (\"eval_loss\" in column):\n",
        "        evals[0].append(column[\"epoch\"])\n",
        "        evals[1].append(column[\"eval_loss\"])\n",
        "\n",
        "for i, column in enumerate(state):\n",
        "    if (\"loss\" in column):\n",
        "        train[0].append(column[\"epoch\"])\n",
        "        train[1].append(column[\"loss\"])\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(evals[0], evals[1], label=\"eval\")\n",
        "plt.plot(train[0], train[1], label=\"train\")\n",
        "plt.title('Cosine with SD')\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.ylim(0, 2.0)\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyNrLMG3IKfJYy9BiErAlo3I",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0359ed9cd3974808af645a0208463ada": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a4791e112d3d471f980214d5ce341f10",
              "IPY_MODEL_88ec7ae09c57497698889a586bac25ee",
              "IPY_MODEL_8cb516b32ce14f559d010e016859c22b"
            ],
            "layout": "IPY_MODEL_705030b7eeab4a81af9f4b6b38adebf9"
          }
        },
        "0453a0a1c8b643359ff8b5afc9330310": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b680b42fd9e246e2909355d511251ff5",
            "max": 45744,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_af5c8e97c00545caab93326d9005f37e",
            "value": 45744
          }
        },
        "057a196745b64187b3235e8e03b3555c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "07ceda4271c74db7938f5c1c964ab8d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b1f9105124e4c98a73411afd510a0a7",
            "placeholder": "",
            "style": "IPY_MODEL_b7446b17d6f945b182b5582e98c40477",
            "value": " 367k/? [00:00&lt;00:00, 20.1MB/s]"
          }
        },
        "0f20408cfd354868964c1ac96e15182d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "111ba9fc9340411b8200851075ae3da8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "12991808ffbb4985949a11aac9a404b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1bdd38742d244c05ba5c09c0d08c73d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_489384badc044a74945ed68d7fbef450",
              "IPY_MODEL_0453a0a1c8b643359ff8b5afc9330310",
              "IPY_MODEL_c1a3dce0157e48cfb90dbaaae87a4a2c"
            ],
            "layout": "IPY_MODEL_afd436f8d349410d9c7c2d7a0dc0c705"
          }
        },
        "1e2830eeff51412d88be2d8c1c25fabc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "239ec50da2214ea890d96330dbafe1d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "241ad8cd6b254189bf918b4c4e66f0d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_70a9a2e1749a4e5f889a90ffcfe698ed",
              "IPY_MODEL_35dbe9271dd6412181d965508716c003",
              "IPY_MODEL_66aaa56e580b425dad6e54f2a00f2162"
            ],
            "layout": "IPY_MODEL_43ae62d6c16d47608fda89136ff0d098"
          }
        },
        "24d835c4b7b04ee282b627ae802065b4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25b2438159304b9797601624984a7cb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8fdf2d0a017425e8f5b1bd30a0f2c90",
            "placeholder": "",
            "style": "IPY_MODEL_c000c04a5fb14c6786ee1d4e2983e260",
            "value": " 926/926 [00:00&lt;00:00, 11610.51 examples/s]"
          }
        },
        "2fdb6c338c7244cd8c8fdcabbf3ca6e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35dbe9271dd6412181d965508716c003": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24d835c4b7b04ee282b627ae802065b4",
            "max": 949,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_239ec50da2214ea890d96330dbafe1d4",
            "value": 949
          }
        },
        "368d6d48189343c08a792e90c09edf96": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "37984bf0b6bf4af8b8e96f78e35ea909": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a4dc12f7546467684ef5745655f7f59": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3deb340cc3d8446ca385474465b0d57e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e3e1bf871b045f99b7ef5bad0fb50e6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43ae62d6c16d47608fda89136ff0d098": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "459d717118a149f8ac13f414d046fe41": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e0d7ac838f748dead98b6d50e20a80b",
            "placeholder": "",
            "style": "IPY_MODEL_8203ea24ccaf42e7981fce149bb1c0f8",
            "value": "Map: 100%"
          }
        },
        "489384badc044a74945ed68d7fbef450": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9c947f871504501be96de21be62d69a",
            "placeholder": "",
            "style": "IPY_MODEL_3a4dc12f7546467684ef5745655f7f59",
            "value": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json: "
          }
        },
        "4f065cfca15642a8bc542a2f1fbfe498": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_52a007efacae40e3b84ad50c64241fe7",
              "IPY_MODEL_8acb0b32346e436ca9df24d57360d3c7",
              "IPY_MODEL_c77858d4289f4fc8b9f20d3b84d57ea6"
            ],
            "layout": "IPY_MODEL_37984bf0b6bf4af8b8e96f78e35ea909"
          }
        },
        "4f5fc896af4b46b5b38545dd167563de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a449fb9e7e8d4f91b831d6ab9209aa99",
              "IPY_MODEL_cc81a70d3c86472989b5940b983fe59f",
              "IPY_MODEL_aa80134e2f944ee9ae2f26ba76d74169"
            ],
            "layout": "IPY_MODEL_a7e8270702414b86ab8d04a0558cff83"
          }
        },
        "4f958913846143a3949c7b0881d5c801": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50f5fdd28ce4430cbcd7d9b823f06658": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52a007efacae40e3b84ad50c64241fe7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e3e1bf871b045f99b7ef5bad0fb50e6",
            "placeholder": "",
            "style": "IPY_MODEL_70af0584e74d483ca042c92ab44af828",
            "value": "Map: 100%"
          }
        },
        "544020e7ba3a4f538c08ec1f5498ce7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "554392641ce94926b63f3aa9b59231da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a508c11db0c454597b9271b15779cf6",
            "placeholder": "",
            "style": "IPY_MODEL_111ba9fc9340411b8200851075ae3da8",
            "value": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json: "
          }
        },
        "55d0b4c05a8f4ca3b8cdbcf6db7bbbbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a17d1414cb046f1a11e27f4bac4645c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e0d7ac838f748dead98b6d50e20a80b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62a0cda9d559481398d7e685b69d452d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66aaa56e580b425dad6e54f2a00f2162": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d14c7c9d8b8d452b9ae62c6bb8ea5b1a",
            "placeholder": "",
            "style": "IPY_MODEL_a37f65ba164443df8c4730ebe946cef9",
            "value": " 949/949 [00:00&lt;00:00, 3347.88 examples/s]"
          }
        },
        "6832f2df5aba4a2984fb476d06ed3810": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b1f9105124e4c98a73411afd510a0a7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "705030b7eeab4a81af9f4b6b38adebf9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70a9a2e1749a4e5f889a90ffcfe698ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_982d940c9e5740d687754b6d6e1d17bd",
            "placeholder": "",
            "style": "IPY_MODEL_0f20408cfd354868964c1ac96e15182d",
            "value": "Map: 100%"
          }
        },
        "70af0584e74d483ca042c92ab44af828": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70ce6a6ce6b6423987482561e873682a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74454516debf4a54b1e546f2dbd837ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "74b0d0d542fb4069861154a9529c5b87": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ce0cc952d5048aa9491f9da9fdcb17f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8203ea24ccaf42e7981fce149bb1c0f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83cbbc391f4b4d369345b8d293ec20b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_554392641ce94926b63f3aa9b59231da",
              "IPY_MODEL_f5fb339912574bcbb6a4930c546c1021",
              "IPY_MODEL_07ceda4271c74db7938f5c1c964ab8d2"
            ],
            "layout": "IPY_MODEL_b7fdaf13a7d74176b2ad902dde8b371d"
          }
        },
        "84c865e110444241829fb055fc141238": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88ec7ae09c57497698889a586bac25ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f59a2ee833bc419081b6e10f85082e48",
            "max": 931,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_368d6d48189343c08a792e90c09edf96",
            "value": 931
          }
        },
        "8a508c11db0c454597b9271b15779cf6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8acb0b32346e436ca9df24d57360d3c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe3d64aa61be496fb000f8410ef3cc07",
            "max": 926,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_057a196745b64187b3235e8e03b3555c",
            "value": 926
          }
        },
        "8cb516b32ce14f559d010e016859c22b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6832f2df5aba4a2984fb476d06ed3810",
            "placeholder": "",
            "style": "IPY_MODEL_12991808ffbb4985949a11aac9a404b6",
            "value": " 931/931 [00:00&lt;00:00, 3402.73 examples/s]"
          }
        },
        "982d940c9e5740d687754b6d6e1d17bd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c0d09550567447fbcdf4fa743872bb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7ee10a2c1094117a8631aa2a7adcd60",
            "placeholder": "",
            "style": "IPY_MODEL_5a17d1414cb046f1a11e27f4bac4645c",
            "value": "Map: 100%"
          }
        },
        "9f7b27a5f0ea4ba6b6a2368d73ca56bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a37f65ba164443df8c4730ebe946cef9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a449fb9e7e8d4f91b831d6ab9209aa99": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50f5fdd28ce4430cbcd7d9b823f06658",
            "placeholder": "",
            "style": "IPY_MODEL_eacd5a5c51eb4a56a90f891a35ee8740",
            "value": "Map: 100%"
          }
        },
        "a4791e112d3d471f980214d5ce341f10": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3d69fd5b42246829bdf3095d3551fb7",
            "placeholder": "",
            "style": "IPY_MODEL_84c865e110444241829fb055fc141238",
            "value": "Map: 100%"
          }
        },
        "a59c9ae50b864d048c7d7b894c9e0fec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9c0d09550567447fbcdf4fa743872bb8",
              "IPY_MODEL_c31b8aed83fb416092f0c552c694a229",
              "IPY_MODEL_cab14b860a26471dab2bdbbd29122e94"
            ],
            "layout": "IPY_MODEL_62a0cda9d559481398d7e685b69d452d"
          }
        },
        "a5a01b0ea128464c92cdbce02dc99ac3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74b0d0d542fb4069861154a9529c5b87",
            "max": 926,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_544020e7ba3a4f538c08ec1f5498ce7b",
            "value": 926
          }
        },
        "a7e8270702414b86ab8d04a0558cff83": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa80134e2f944ee9ae2f26ba76d74169": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f958913846143a3949c7b0881d5c801",
            "placeholder": "",
            "style": "IPY_MODEL_2fdb6c338c7244cd8c8fdcabbf3ca6e7",
            "value": " 949/949 [00:00&lt;00:00, 11326.09 examples/s]"
          }
        },
        "af21f480704f4d74a8f88cfc54473d0c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af4684ee39274c98912e6ccbaa8fab92": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af5c8e97c00545caab93326d9005f37e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "afd436f8d349410d9c7c2d7a0dc0c705": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0a9794e325b4906ab04cc03516a44ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b680b42fd9e246e2909355d511251ff5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7446b17d6f945b182b5582e98c40477": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7fdaf13a7d74176b2ad902dde8b371d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be30e8d4605c41a39130f9fb8e31a029": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf7d168cc8ef4a1ca37f176a23061f14": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c000c04a5fb14c6786ee1d4e2983e260": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1a3dce0157e48cfb90dbaaae87a4a2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af4684ee39274c98912e6ccbaa8fab92",
            "placeholder": "",
            "style": "IPY_MODEL_55d0b4c05a8f4ca3b8cdbcf6db7bbbbf",
            "value": " 367k/? [00:00&lt;00:00, 16.9MB/s]"
          }
        },
        "c31b8aed83fb416092f0c552c694a229": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be30e8d4605c41a39130f9fb8e31a029",
            "max": 931,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b0a9794e325b4906ab04cc03516a44ef",
            "value": 931
          }
        },
        "c3d69fd5b42246829bdf3095d3551fb7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c77858d4289f4fc8b9f20d3b84d57ea6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e2830eeff51412d88be2d8c1c25fabc",
            "placeholder": "",
            "style": "IPY_MODEL_7ce0cc952d5048aa9491f9da9fdcb17f",
            "value": " 926/926 [00:00&lt;00:00, 3532.43 examples/s]"
          }
        },
        "cab14b860a26471dab2bdbbd29122e94": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af21f480704f4d74a8f88cfc54473d0c",
            "placeholder": "",
            "style": "IPY_MODEL_9f7b27a5f0ea4ba6b6a2368d73ca56bf",
            "value": " 931/931 [00:00&lt;00:00, 12395.71 examples/s]"
          }
        },
        "cc81a70d3c86472989b5940b983fe59f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70ce6a6ce6b6423987482561e873682a",
            "max": 949,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_74454516debf4a54b1e546f2dbd837ab",
            "value": 949
          }
        },
        "d14c7c9d8b8d452b9ae62c6bb8ea5b1a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d264a1b855734178aa27c3e896a8e0e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d9c947f871504501be96de21be62d69a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea6fcff1a76e43868bdfb4d02951d072": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_459d717118a149f8ac13f414d046fe41",
              "IPY_MODEL_a5a01b0ea128464c92cdbce02dc99ac3",
              "IPY_MODEL_25b2438159304b9797601624984a7cb0"
            ],
            "layout": "IPY_MODEL_3deb340cc3d8446ca385474465b0d57e"
          }
        },
        "eacd5a5c51eb4a56a90f891a35ee8740": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f59a2ee833bc419081b6e10f85082e48": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5fb339912574bcbb6a4930c546c1021": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf7d168cc8ef4a1ca37f176a23061f14",
            "max": 45744,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d264a1b855734178aa27c3e896a8e0e0",
            "value": 45744
          }
        },
        "f7ee10a2c1094117a8631aa2a7adcd60": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8fdf2d0a017425e8f5b1bd30a0f2c90": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe3d64aa61be496fb000f8410ef3cc07": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}